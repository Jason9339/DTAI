# food_recognition.py - é£Ÿç‰©è¾¨è­˜æ¨¡çµ„
import random
import gradio as gr
from typing import Dict
from PIL import Image
import os
import pandas as pd
from config import FOOD_DATABASE
import numpy as np

# å˜—è©¦å°å…¥PyTorchï¼Œå¦‚æœå¤±æ•—å‰‡ä½¿ç”¨æ¨¡æ“¬æ¨¡å¼
try:
    import torch
    import torch.nn as nn
    from torchvision import transforms
    import timm  # ç”¨æ–¼è¼‰å…¥é è¨“ç·´æ¨¡å‹æ¶æ§‹
    TORCH_AVAILABLE = True
    print("âœ… PyTorchå·²è¼‰å…¥ï¼Œä½¿ç”¨å®Œæ•´AIæ¨¡å‹åŠŸèƒ½")
except ImportError:
    TORCH_AVAILABLE = False
    print("âš ï¸ PyTorchæœªå®‰è£ï¼Œä½¿ç”¨æ¨¡æ“¬æ¨¡å¼")
    # å‰µå»ºæ¨¡æ“¬çš„torchæ¨¡çµ„
    class MockTorch:
        @staticmethod
        def device(device_type):
            return "cpu"
        
        @staticmethod  
        def no_grad():
            class MockContext:
                def __enter__(self):
                    return self
                def __exit__(self, *args):
                    pass
            return MockContext()
    
    torch = MockTorch()

# å…¨åŸŸè®Šæ•¸ä¾†å¿«å–å·²è¼‰å…¥çš„æ¨¡å‹
_loaded_models = {}

# è¨“ç·´æ™‚ä½¿ç”¨çš„æ¨™ç±¤åˆ—è¡¨ (å¿…é ˆèˆ‡è¨“ç·´æ™‚ä¸€è‡´)
TRAINING_LABELS = ['Abalone', 'Abalonemushroom', 'Achoy', 'Adzukibean', 'Alfalfasprouts', 'Almond', 'Apple', 'Asparagus', 'Avocado', 'Babycorn', 'Bambooshoot', 'Banana', 'Beeftripe', 'Beetroot', 'Birds-nestfern', 'Birdsnest', 'Bittermelon', 'Blackmoss', 'Blackpepper', 'Blacksoybean', 'Blueberry', 'Bokchoy', 'Brownsugar', 'Buckwheat', 'Cabbage', 'Cardamom', 'Carrot', 'Cashewnut', 'Cauliflower', 'Celery', 'Centuryegg', 'Cheese', 'Cherry', 'Chestnut', 'Chilipepper', 'Chinesebayberry', 'Chinesechiveflowers', 'Chinesechives', 'Chinesekale', 'Cilantro', 'Cinnamon', 'Clove', 'Cocoa', 'Coconut', 'Corn', 'Cowpea', 'Crab', 'Cream', 'Cucumber', 'Daikon', 'Dragonfruit', 'Driedpersimmon', 'Driedscallop', 'Driedshrimp', 'Duckblood', 'Durian', 'Eggplant', 'Enokimushroom', 'Fennel', 'Fig', 'Fishmint', 'Freshwaterclam', 'Garlic', 'Ginger', 'Glutinousrice', 'Gojileaves', 'Grape', 'Grapefruit', 'GreenSoybean', 'Greenbean', 'Greenbellpepper', 'Greenonion', 'Guava', 'Gynuradivaricata', 'Headingmustard', 'Honey', 'Jicama', 'Jobstears', 'Jujube', 'Kale', 'Kelp', 'Kidneybean', 'Kingoystermushroom', 'Kiwifruit', 'Kohlrabi', 'Kumquat', 'Lettuce', 'Limabean', 'Lime', 'Lobster', 'Longan', 'Lotusroot', 'Lotusseed', 'Luffa', 'Lychee', 'Madeira_vine', 'Maitakemushroom', 'Mandarin', 'Mango', 'Mangosteen', 'Milk', 'Millet', 'Minongmelon', 'Mint', 'Mungbean', 'Napacabbage', 'Natto', 'Nori', 'Nutmeg', 'Oat', 'Octopus', 'Okinawaspinach', 'Okra', 'Olive', 'Onion', 'Orange', 'Oystermushroom', 'Papaya', 'Parsley', 'Passionfruit', 'Pea', 'Peach', 'Peanut', 'Pear', 'Pepper', 'Perilla', 'Persimmon', 'Pickledmustardgreens', 'Pineapple', 'Pinenut', 'Plum', 'Pomegranate', 'Pomelo', 'Porktripe', 'Potato', 'Pumpkin', 'Pumpkinseed', 'Quailegg', 'Radishsprouts', 'Rambutan', 'Raspberry', 'Redamaranth', 'Reddate', 'Rice', 'Rosemary', 'Safflower', 'Saltedpotherbmustard', 'Seacucumber', 'Seaurchin', 'Sesameseed', 'Shaggymanemushroom', 'Shiitakemushroom', 'Shrimp', 'Snowfungus', 'Soybean', 'Soybeansprouts', 'Soysauce', 'Staranise', 'Starfruit', 'Strawberry', 'Strawmushroom', 'Sugarapple', 'Sunflowerseed', 'Sweetpotato', 'Sweetpotatoleaves', 'Taro', 'Thyme', 'Tofu', 'Tomato', 'Wasabi', 'Waterbamboo', 'Watercaltrop', 'Watermelon', 'Waterspinach', 'Waxapple', 'Wheatflour', 'Wheatgrass', 'Whitepepper', 'Wintermelon', 'Woodearmushroom', 'Yapear', 'Yauchoy', 'spinach']

def normalize_name(name):
    """
    å°‡è‹±æ–‡åç¨±è½‰æ›ç‚ºæ­£è¦åŒ–æ ¼å¼ï¼ˆç§»é™¤ç©ºæ ¼ã€é€£å­—ç¬¦ç­‰ï¼Œè½‰ç‚ºå°å¯«ï¼‰
    Args:
        name: éœ€è¦æ­£è¦åŒ–çš„åç¨±
    Returns:
        æ­£è¦åŒ–å¾Œçš„åç¨±
    """
    if pd.isna(name) or not name:
        return ""
    # ç§»é™¤ç©ºæ ¼ã€é€£å­—ç¬¦ã€åº•ç·šï¼Œè½‰ç‚ºå°å¯«
    normalized = str(name).replace(" ", "").replace("-", "").replace("_", "").lower()
    return normalized

def map_training_label_to_database(training_label: str) -> str:
    """
    å°‡è¨“ç·´æ¨™ç±¤æ˜ å°„åˆ°è³‡æ–™åº«ä¸­çš„é£Ÿç‰©åç¨±
    Args:
        training_label: å¾æ¨¡å‹é æ¸¬å¾—åˆ°çš„è¨“ç·´æ¨™ç±¤ (è‹±æ–‡)
    Returns:
        å°æ‡‰çš„è³‡æ–™åº«é£Ÿç‰©åç¨± (ä¸­æ–‡)ï¼Œå¦‚æœæ‰¾ä¸åˆ°å‰‡è¿”å› None
    """
    # æ¨¡å‹è¼¸å‡ºæ˜¯è‹±æ–‡ï¼Œç›´æ¥ä½¿ç”¨æ­£è¦åŒ–åç¨±åŒ¹é…è‹±æ–‡åç¨±
    normalized_training = normalize_name(training_label)
    
    # æª¢æŸ¥è³‡æ–™åº«ä¸­æ‰€æœ‰è‹±æ–‡åç¨±çš„æ­£è¦åŒ–ç‰ˆæœ¬
    for chinese_name, food_info in FOOD_DATABASE.items():
        english_name = food_info.get("è‹±æ–‡å", "")
        if english_name:
            normalized_english = normalize_name(english_name)
            if normalized_training == normalized_english:
                print(f"è‹±æ–‡åç¨±åŒ¹é…æˆåŠŸ: '{training_label}' -> '{chinese_name}' (é€šéè‹±æ–‡å: '{english_name}')")
                return chinese_name
    
    # å¦‚æœæ‰¾ä¸åˆ°åŒ¹é…é …ç›®ï¼Œè¿”å› None
    print(f"ç„¡æ³•æ‰¾åˆ°åŒ¹é…é …ç›®: '{training_label}'")
    return None

def create_model_architecture(model_name: str, num_classes: int = None, state_dict: dict = None):
    """
    æ ¹æ“šæ¨¡å‹åç¨±å‰µå»ºå°æ‡‰çš„æ¨¡å‹æ¶æ§‹
    Args:
        model_name: æ¨¡å‹åç¨±
        num_classes: åˆ†é¡æ•¸é‡ï¼Œå¦‚æœç‚º None å‰‡è‡ªå‹•æ¨æ¸¬
        state_dict: æ¨¡å‹çš„ state_dictï¼Œç”¨æ–¼æª¢æ¸¬æ¶æ§‹è®Šé«”
    """
    # å¦‚æœæ²’æœ‰æŒ‡å®š num_classesï¼Œä½¿ç”¨ 183 å€‹é¡åˆ¥
    if num_classes is None:
        num_classes = 183
    
    if 'swinv2' in model_name.lower():
        # Swin Transformer V2 - ä½¿ç”¨èˆ‡è¨“ç·´æ™‚ç›¸åŒçš„æ¨¡å‹æ¶æ§‹
        model = timm.create_model('swinv2_base_window12_192', 
                                pretrained=False, 
                                num_classes=num_classes)
    elif 'swin' in model_name.lower() and 'swinv2' not in model_name.lower():
        # Swin Transformer V1 - ç¢ºä¿ä¸æ˜¯ V2
        model = timm.create_model('swin_base_patch4_window7_224', 
                                pretrained=False, 
                                num_classes=num_classes)
    elif 'vit' in model_name.lower():
        # Vision Transformer
        model = timm.create_model('vit_base_patch16_224', 
                                pretrained=False, 
                                num_classes=num_classes)
    elif 'convnext' in model_name.lower():
        # ConvNeXt - ä½¿ç”¨ torchvisionï¼ˆèˆ‡ç”¨æˆ¶è¨“ç·´ç¨‹å¼ç¢¼ä¸€è‡´ï¼‰
        from torchvision import models
        import torch.nn as nn
        
        model = models.convnext_base(weights=None)
        
        # ä¿®æ”¹åˆ†é¡å™¨çš„æœ€å¾Œä¸€å±¤ä»¥åŒ¹é…é¡åˆ¥æ•¸
        model.classifier[2] = nn.Linear(model.classifier[2].in_features, num_classes)
    elif 'efficientnet' in model_name.lower():
        # EfficientNet - ä½¿ç”¨ torchvisionï¼ˆèˆ‡ç”¨æˆ¶è¨“ç·´ç¨‹å¼ç¢¼ä¸€è‡´ï¼‰
        from torchvision import models
        import torch.nn as nn
        
        if 'b5' in model_name.lower():
            model = models.efficientnet_b5(weights=None)
        elif 'b4' in model_name.lower():
            model = models.efficientnet_b4(weights=None)
        elif 'b3' in model_name.lower():
            model = models.efficientnet_b3(weights=None)
        elif 'b2' in model_name.lower():
            model = models.efficientnet_b2(weights=None)
        elif 'b1' in model_name.lower():
            model = models.efficientnet_b1(weights=None)
        else:
            # é è¨­ä½¿ç”¨ B0
            model = models.efficientnet_b0(weights=None)
        
        # ä¿®æ”¹åˆ†é¡å™¨çš„æœ€å¾Œä¸€å±¤ä»¥åŒ¹é…é¡åˆ¥æ•¸
        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)
    elif 'vgg' in model_name.lower():
        # VGG
        model = timm.create_model('vgg16', 
                                pretrained=False, 
                                num_classes=num_classes)
    elif 'densenet' in model_name.lower():
        # DenseNet - æª¢æ¸¬è®Šé«”
        if state_dict is not None:
            densenet_variant = detect_densenet_variant(state_dict)
            print(f"æª¢æ¸¬åˆ° DenseNet è®Šé«”: {densenet_variant}")
        else:
            # å˜—è©¦å¾æ¨¡å‹åç¨±æ¨æ¸¬
            if 'densenet201' in model_name.lower():
                densenet_variant = 'densenet201'
            elif 'densenet169' in model_name.lower():
                densenet_variant = 'densenet169'
            elif 'densenet161' in model_name.lower():
                densenet_variant = 'densenet161'
            else:
                densenet_variant = 'densenet121'  # é è¨­å€¼
        
        model = timm.create_model(densenet_variant, 
                                pretrained=False, 
                                num_classes=num_classes)
    elif 'resnet' in model_name.lower():
        # ResNet
        model = timm.create_model('resnet50', 
                                pretrained=False, 
                                num_classes=num_classes)
    else:
        # é»˜èªä½¿ç”¨ ResNet50
        model = timm.create_model('resnet50', 
                                pretrained=False, 
                                num_classes=num_classes)
    
    return model

def clean_state_dict_keys(state_dict):
    """
    æ¸…ç† state_dict ä¸­çš„éµåï¼Œç§»é™¤å¯èƒ½çš„å‰ç¶´ï¼ˆå¦‚ "module."ï¼‰
    Args:
        state_dict: åŸå§‹çš„ state_dict
    Returns:
        æ¸…ç†å¾Œçš„ state_dict
    """
    cleaned_state_dict = {}
    for key, value in state_dict.items():
        # ç§»é™¤ "module." å‰ç¶´
        clean_key = key
        if key.startswith('module.'):
            clean_key = key[7:]  # ç§»é™¤ "module." (7å€‹å­—ç¬¦)
        
        # ç§»é™¤å…¶ä»–å¯èƒ½çš„å‰ç¶´
        if clean_key.startswith('model.'):
            clean_key = clean_key[6:]  # ç§»é™¤ "model."
            
        cleaned_state_dict[clean_key] = value
    
    return cleaned_state_dict

def filter_incompatible_keys(state_dict, model_architecture):
    """
    éæ¿¾ state_dict ä¸­èˆ‡æ¨¡å‹æ¶æ§‹ä¸ç›¸å®¹çš„éµ
    ç‰¹åˆ¥è™•ç† Swin Transformer æ¨¡å‹çš„å•é¡Œéµ
    Args:
        state_dict: åŸå§‹çš„ state_dict
        model_architecture: æ¨¡å‹æ¶æ§‹ç‰©ä»¶
    Returns:
        éæ¿¾å¾Œçš„ state_dict
    """
    # å®šç¾©éœ€è¦éæ¿¾æ‰çš„éµæ¨¡å¼ï¼ˆé€™äº›æ˜¯è¨“ç·´æ™‚ç”Ÿæˆçš„ç·©å­˜ï¼Œè¼‰å…¥æ™‚ä¸éœ€è¦ï¼‰
    incompatible_patterns = [
        'relative_position_index',  # Swin Transformer ç›¸å°ä½ç½®ç´¢å¼•
        'attn_mask',               # æ³¨æ„åŠ›æ©ç¢¼
        'relative_coords_table',   # ç›¸å°åº§æ¨™è¡¨
        'relative_position_bias_table'  # ç›¸å°ä½ç½®åç½®è¡¨
    ]
    
    filtered_state_dict = {}
    skipped_keys = []
    
    for key, value in state_dict.items():
        # æª¢æŸ¥æ˜¯å¦åŒ…å«ä¸ç›¸å®¹çš„æ¨¡å¼
        should_skip = False
        for pattern in incompatible_patterns:
            if pattern in key:
                should_skip = True
                skipped_keys.append(key)
                break
        
        if not should_skip:
            filtered_state_dict[key] = value
    
    if skipped_keys:
        print(f"éæ¿¾æ‰ä¸ç›¸å®¹çš„éµ: {skipped_keys}")
    
    return filtered_state_dict

def get_num_classes_from_state_dict(state_dict):
    """
    å¾ state_dict ä¸­æ¨æ–·æ¨¡å‹çš„é¡åˆ¥æ•¸é‡
    """
    # å…ˆæ¸…ç†éµå
    cleaned_state_dict = clean_state_dict_keys(state_dict)
    
    # å°‹æ‰¾åˆ†é¡å±¤çš„æ¬Šé‡
    for key in cleaned_state_dict.keys():
        # è™•ç†ä¸åŒæ¨¡å‹çš„åˆ†é¡å™¨å‘½å
        if ('head.fc.weight' in key or 'classifier.weight' in key or 'fc.weight' in key or 
            'classifier.1.weight' in key):  # EfficientNet çš„åˆ†é¡å™¨
            return cleaned_state_dict[key].shape[0]
        if ('head.fc.bias' in key or 'classifier.bias' in key or 'fc.bias' in key or 
            'classifier.1.bias' in key):  # EfficientNet çš„åˆ†é¡å™¨
            return cleaned_state_dict[key].shape[0]
    
    # å¦‚æœæ‰¾ä¸åˆ°ï¼Œä½¿ç”¨é è¨­å€¼
    return 183

def detect_densenet_variant(state_dict):
    """
    å¾ state_dict ä¸­æª¢æ¸¬ DenseNet çš„è®Šé«”
    """
    cleaned_state_dict = clean_state_dict_keys(state_dict)
    
    # æª¢æŸ¥åˆ†é¡å™¨çš„è¼¸å…¥ç‰¹å¾µæ•¸é‡
    for key in cleaned_state_dict.keys():
        if 'classifier.weight' in key:
            feature_size = cleaned_state_dict[key].shape[1]
            if feature_size == 1024:
                return 'densenet121'
            elif feature_size == 1664:
                return 'densenet169'
            elif feature_size == 1920:
                return 'densenet201'
            elif feature_size == 2208:
                return 'densenet161'
    
    # å¦‚æœæ‰¾ä¸åˆ°åˆ†é¡å™¨ï¼Œå˜—è©¦æª¢æŸ¥ norm5 å±¤
    for key in cleaned_state_dict.keys():
        if 'norm5.weight' in key or 'features.norm5.weight' in key:
            feature_size = cleaned_state_dict[key].shape[0]
            if feature_size == 1024:
                return 'densenet121'
            elif feature_size == 1664:
                return 'densenet169'
            elif feature_size == 1920:
                return 'densenet201'
            elif feature_size == 2208:
                return 'densenet161'
    
    # é è¨­è¿”å› densenet121
    return 'densenet121'

def load_model(model_name: str, model_path: str = None):
    """
    è¼‰å…¥ PyTorch æ¨¡å‹ (å¦‚æœPyTorchå¯ç”¨) æˆ–è¿”å›æ¨¡æ“¬æ¨¡å‹
    Args:
        model_name: æ¨¡å‹åç¨±
        model_path: æ¨¡å‹æª”æ¡ˆè·¯å¾‘ï¼Œå¦‚æœç‚º None å‰‡ä½¿ç”¨é è¨­è·¯å¾‘
    """
    if not TORCH_AVAILABLE:
        print(f"âš ï¸ PyTorchæœªå®‰è£ï¼Œ{model_name} ä½¿ç”¨æ¨¡æ“¬æ¨¡å¼")
        return None
        
    if model_name in _loaded_models:
        return _loaded_models[model_name]
    
    # ç‰¹æ®Šè™•ç† EfficientNet æ¨¡å‹
    if 'efficientnet' in model_name.lower():
        model = load_efficientnet_model(model_name, model_path)
        if model is not None:
            _loaded_models[model_name] = model
        return model
    
    # ç‰¹æ®Šè™•ç† Swin Transformer æ¨¡å‹
    if 'swin' in model_name.lower():
        model = load_swin_model(model_name, model_path)
        if model is not None:
            _loaded_models[model_name] = model
        return model
    
    # ç‰¹æ®Šè™•ç† ConvNeXt æ¨¡å‹
    if 'convnext' in model_name.lower():
        model = load_convnext_model(model_name, model_path)
        if model is not None:
            _loaded_models[model_name] = model
        return model
    
    # ç‰¹æ®Šè™•ç† VGG æ¨¡å‹
    if 'vgg' in model_name.lower():
        model = load_vgg_model(model_name, model_path)
        if model is not None:
            _loaded_models[model_name] = model
        return model
        
    if model_path is None:
        model_path = f"./model/{model_name}.pth"
    
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨: {model_path}ï¼Œä½¿ç”¨æ¨¡æ“¬æ¨¡å¼")
        return None
    
    try:
        # è¼‰å…¥æ¨¡å‹
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # è¼‰å…¥æª¢æŸ¥é»
        checkpoint = torch.load(model_path, map_location=device)
        
        # æª¢æŸ¥è¼‰å…¥çš„æ˜¯ä»€éº¼é¡å‹çš„ç‰©ä»¶
        if isinstance(checkpoint, dict):
            # å¦‚æœæ˜¯å­—å…¸ï¼Œå¯èƒ½åŒ…å« model_state_dict
            if 'model_state_dict' in checkpoint:
                # æª¢æŸ¥æ¨¡å‹çš„é¡åˆ¥æ•¸é‡
                state_dict = checkpoint['model_state_dict']
                num_classes = get_num_classes_from_state_dict(state_dict)
                
                # å‰µå»ºæ¨¡å‹æ¶æ§‹ï¼ˆå‚³å…¥ state_dict ç”¨æ–¼æª¢æ¸¬ï¼‰
                model = create_model_architecture(model_name, num_classes, state_dict)
                
                # æ¸…ç† state_dict éµåï¼Œç§»é™¤ "module." å‰ç¶´
                cleaned_state_dict = clean_state_dict_keys(state_dict)
                
                # éæ¿¾ä¸ç›¸å®¹çš„éµ
                filtered_state_dict = filter_incompatible_keys(cleaned_state_dict, model)
                
                # è¼‰å…¥æ¬Šé‡ï¼Œä½¿ç”¨ strict=False ä¾†å…è¨±éƒ¨åˆ†è¼‰å…¥
                try:
                    model.load_state_dict(filtered_state_dict, strict=True)
                    print(f"æˆåŠŸè¼‰å…¥æ¨¡å‹æ¶æ§‹ä¸¦è¼‰å…¥ model_state_dict (é¡åˆ¥æ•¸: {num_classes})")
                except RuntimeError as e:
                    if "Missing key(s)" in str(e) or "Unexpected key(s)" in str(e):
                        print(f"ä½¿ç”¨ strict=False æ¨¡å¼è¼‰å…¥: {e}")
                        model.load_state_dict(filtered_state_dict, strict=False)
                        print(f"æˆåŠŸè¼‰å…¥æ¨¡å‹æ¶æ§‹ä¸¦è¼‰å…¥ model_state_dict (é¡åˆ¥æ•¸: {num_classes}, éƒ¨åˆ†è¼‰å…¥)")
                    else:
                        raise e
                
                model.eval()
                
            elif 'state_dict' in checkpoint:
                # æª¢æŸ¥æ¨¡å‹çš„é¡åˆ¥æ•¸é‡
                state_dict = checkpoint['state_dict']
                num_classes = get_num_classes_from_state_dict(state_dict)
                
                # å‰µå»ºæ¨¡å‹æ¶æ§‹ï¼ˆå‚³å…¥ state_dict ç”¨æ–¼æª¢æ¸¬ï¼‰
                model = create_model_architecture(model_name, num_classes, state_dict)
                
                # æ¸…ç† state_dict éµåï¼Œç§»é™¤ "module." å‰ç¶´
                cleaned_state_dict = clean_state_dict_keys(state_dict)
                
                # éæ¿¾ä¸ç›¸å®¹çš„éµ
                filtered_state_dict = filter_incompatible_keys(cleaned_state_dict, model)
                
                # è¼‰å…¥æ¬Šé‡ï¼Œä½¿ç”¨ strict=False ä¾†å…è¨±éƒ¨åˆ†è¼‰å…¥
                try:
                    model.load_state_dict(filtered_state_dict, strict=True)
                    print(f"æˆåŠŸè¼‰å…¥æ¨¡å‹æ¶æ§‹ä¸¦è¼‰å…¥ state_dict (é¡åˆ¥æ•¸: {num_classes})")
                except RuntimeError as e:
                    if "Missing key(s)" in str(e) or "Unexpected key(s)" in str(e):
                        print(f"ä½¿ç”¨ strict=False æ¨¡å¼è¼‰å…¥: {e}")
                        model.load_state_dict(filtered_state_dict, strict=False)
                        print(f"æˆåŠŸè¼‰å…¥æ¨¡å‹æ¶æ§‹ä¸¦è¼‰å…¥ state_dict (é¡åˆ¥æ•¸: {num_classes}, éƒ¨åˆ†è¼‰å…¥)")
                    else:
                        raise e
                
                model.eval()
                
            else:
                # ç›´æ¥æ˜¯ state_dict (OrderedDict)
                num_classes = get_num_classes_from_state_dict(checkpoint)
                
                # å‰µå»ºæ¨¡å‹æ¶æ§‹ï¼ˆå‚³å…¥ state_dict ç”¨æ–¼æª¢æ¸¬ï¼‰
                model = create_model_architecture(model_name, num_classes, checkpoint)
                
                # æ¸…ç† state_dict éµåï¼Œç§»é™¤ "module." å‰ç¶´
                cleaned_state_dict = clean_state_dict_keys(checkpoint)
                
                # éæ¿¾ä¸ç›¸å®¹çš„éµ
                filtered_state_dict = filter_incompatible_keys(cleaned_state_dict, model)
                
                # è¼‰å…¥æ¬Šé‡ï¼Œä½¿ç”¨ strict=False ä¾†å…è¨±éƒ¨åˆ†è¼‰å…¥
                try:
                    model.load_state_dict(filtered_state_dict, strict=True)
                    print(f"æˆåŠŸè¼‰å…¥æ¨¡å‹æ¶æ§‹ä¸¦è¼‰å…¥ç´” state_dict (é¡åˆ¥æ•¸: {num_classes})")
                except RuntimeError as e:
                    if "Missing key(s)" in str(e) or "Unexpected key(s)" in str(e):
                        print(f"ä½¿ç”¨ strict=False æ¨¡å¼è¼‰å…¥: {e}")
                        model.load_state_dict(filtered_state_dict, strict=False)
                        print(f"æˆåŠŸè¼‰å…¥æ¨¡å‹æ¶æ§‹ä¸¦è¼‰å…¥ç´” state_dict (é¡åˆ¥æ•¸: {num_classes}, éƒ¨åˆ†è¼‰å…¥)")
                    else:
                        raise e
                
                model.eval()
        else:
            # ç›´æ¥æ˜¯æ¨¡å‹ç‰©ä»¶
            model = checkpoint
            model.eval()
            print(f"ç›´æ¥è¼‰å…¥å®Œæ•´æ¨¡å‹ç‰©ä»¶")
        
        # ç¢ºä¿æ¨¡å‹åœ¨æ­£ç¢ºçš„è¨­å‚™ä¸Š
        model = model.to(device)
        
        # å¿«å–æ¨¡å‹
        _loaded_models[model_name] = model
        
        print(f"æˆåŠŸè¼‰å…¥æ¨¡å‹: {model_name} (è¨­å‚™: {device})")
        return model
        
    except Exception as e:
        print(f"è¼‰å…¥æ¨¡å‹å¤±æ•—: {e}")
        return None

def preprocess_image(image: Image.Image, model_name: str = None):
    """
    åœ–ç‰‡é è™•ç† (å¦‚æœPyTorchå¯ç”¨) æˆ–æ¨¡æ“¬é è™•ç†
    Args:
        image: è¼¸å…¥åœ–ç‰‡
        model_name: æ¨¡å‹åç¨±ï¼Œç”¨æ–¼æ±ºå®šè¼¸å…¥å°ºå¯¸
    """
    if not TORCH_AVAILABLE:
        # æ¨¡æ“¬æ¨¡å¼ï¼Œåªé€²è¡ŒåŸºæœ¬çš„åœ–ç‰‡æª¢æŸ¥
        if image.mode != 'RGB':
            image = image.convert('RGB')
        return np.array(image)  # è¿”å›numpyæ•¸çµ„ä½œç‚ºæ¨¡æ“¬tensor
    
    # æ ¹æ“šæ¨¡å‹é¡å‹æ±ºå®šè¼¸å…¥å°ºå¯¸
    if model_name and 'swinv2' in model_name.lower():
        input_size = 192  # Swin Transformer V2 è¨“ç·´æ™‚ä½¿ç”¨ 192x192
    else:
        input_size = 224  # å…¶ä»–æ¨¡å‹ä½¿ç”¨ 224x224
    
    transform = transforms.Compose([
        transforms.Resize((input_size, input_size)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                           std=[0.229, 0.224, 0.225])
    ])
    
    # ç¢ºä¿åœ–ç‰‡æ˜¯ RGB æ ¼å¼
    if image.mode != 'RGB':
        image = image.convert('RGB')
    
    return transform(image).unsqueeze(0)

def classify_food_image(image: Image.Image, model_name: str) -> Dict:
    """
    ä½¿ç”¨æŒ‡å®šçš„ PyTorch æ¨¡å‹é€²è¡Œé£Ÿç‰©è¾¨è­˜ (æˆ–æ¨¡æ“¬è¾¨è­˜)
    Args:
        image: è¼¸å…¥åœ–ç‰‡
        model_name: è¦ä½¿ç”¨çš„æ¨¡å‹åç¨±
    """
    if image is None:
        return {"éŒ¯èª¤": "è«‹ä¸Šå‚³é£Ÿç‰©åœ–ç‰‡"}
    
    if not model_name:
        return {"éŒ¯èª¤": "è«‹æŒ‡å®šæ¨¡å‹åç¨±"}
    
    try:
        # è¼‰å…¥æ¨¡å‹
        model = load_model(model_name)
        
        if model is None or not TORCH_AVAILABLE:
            # å¦‚æœæ¨¡å‹è¼‰å…¥å¤±æ•—æˆ–PyTorchä¸å¯ç”¨ï¼Œä½¿ç”¨æ¨¡æ“¬æ¨¡å¼
            print(f"ğŸ² æ¨¡å‹ {model_name} ä½¿ç”¨æ¨¡æ“¬æ¨¡å¼é€²è¡Œè¾¨è­˜")
            food_names = list(FOOD_DATABASE.keys())
            # åŸºæ–¼åœ–ç‰‡ç‰¹æ€§çš„ç°¡å–®æ¨¡æ“¬é‚è¼¯
            np.random.seed(hash(str(image.size)) % 1000)  # åŸºæ–¼åœ–ç‰‡å°ºå¯¸ç”¢ç”Ÿç¨®å­
            recognized_food = np.random.choice(food_names)
            confidence = np.random.randint(82, 96)  # æ¨¡æ“¬ä¿¡å¿ƒåº¦
        else:
            # ä½¿ç”¨çœŸå¯¦æ¨¡å‹é€²è¡Œé æ¸¬
            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
            
            # åœ–ç‰‡é è™•ç†
            input_tensor = preprocess_image(image, model_name).to(device)
            
            # æ¨¡å‹æ¨è«–
            with torch.no_grad():
                outputs = model(input_tensor)
                
                # å‡è¨­æ¨¡å‹è¼¸å‡ºæ˜¯é¡åˆ¥ç´¢å¼•æˆ–æ©Ÿç‡åˆ†å¸ƒ
                if len(outputs.shape) > 1:
                    predicted_idx = torch.argmax(outputs, dim=1).item()
                    # è¨ˆç®—ä¿¡å¿ƒåº¦
                    probabilities = torch.softmax(outputs, dim=1)
                    confidence = int(probabilities[0][predicted_idx].item() * 100)
                else:
                    predicted_idx = outputs.item()
                    confidence = random.randint(85, 98)
                
                # å°‡é æ¸¬ç´¢å¼•è½‰æ›ç‚ºé£Ÿç‰©åç¨±
                # ä½¿ç”¨è¨“ç·´æ™‚çš„æ¨™ç±¤åˆ—è¡¨é€²è¡Œæ˜ å°„
                if predicted_idx < len(TRAINING_LABELS):
                    recognized_food = TRAINING_LABELS[predicted_idx]
                    print(f"AIè¾¨è­˜çµæœ: {recognized_food} (ç´¢å¼•: {predicted_idx}, ä¿¡å¿ƒåº¦: {confidence}%)")
                else:
                    print(f"è­¦å‘Š: é æ¸¬ç´¢å¼• {predicted_idx} è¶…å‡ºç¯„åœï¼Œä½¿ç”¨éš¨æ©Ÿé¸æ“‡")
                    food_names = list(FOOD_DATABASE.keys())
                    recognized_food = random.choice(food_names)
                    confidence = random.randint(75, 90)

        # å¾è³‡æ–™åº«ç²å–é£Ÿç‰©è³‡è¨Š
        # é¦–å…ˆå˜—è©¦ç›´æ¥åŒ¹é…ï¼Œå¦‚æœå¤±æ•—å‰‡å˜—è©¦æ˜ å°„
        if recognized_food in FOOD_DATABASE:
            food_info = FOOD_DATABASE[recognized_food]
        else:
            # å˜—è©¦æ˜ å°„åˆ°è³‡æ–™åº«ä¸­çš„é£Ÿç‰©åç¨±
            mapped_food = map_training_label_to_database(recognized_food)
            if mapped_food and mapped_food in FOOD_DATABASE:
                food_info = FOOD_DATABASE[mapped_food]
                recognized_food = mapped_food  # ä½¿ç”¨æ˜ å°„å¾Œçš„åç¨±
            else:
                return {"éŒ¯èª¤": f"è¾¨è­˜çš„é£Ÿç‰© '{recognized_food}' ç„¡æ³•åœ¨è³‡æ–™åº«ä¸­æ‰¾åˆ°å°æ‡‰é …ç›®"}
        
        # æ±ºå®šç‹€æ…‹æ¨™ç¤º
        status_prefix = "ğŸ²" if (model is None or not TORCH_AVAILABLE) else "ğŸ¤–"
        
        result = {
            "è¾¨è­˜é£Ÿç‰©": recognized_food,
            "è‹±æ–‡å": food_info.get("è‹±æ–‡å", "unknown"),
            "äº”æ€§å±¬æ€§": food_info["äº”æ€§"],
            "ä½¿ç”¨æ¨¡å‹": f"{status_prefix} {model_name}",
            "ä¿¡å¿ƒåº¦": f"{confidence}%",
            "æ¨¡å¼": "æ¨¡æ“¬æ¨¡å¼" if (model is None or not TORCH_AVAILABLE) else "AIæ¨¡å¼"
        }
        
        return result
        
    except Exception as e:
        return {"éŒ¯èª¤": f"è¾¨è­˜éç¨‹ç™¼ç”ŸéŒ¯èª¤: {str(e)}"}

def classify_with_all_models(image: Image.Image) -> Dict:
    """
    ä½¿ç”¨æ‰€æœ‰å¯ç”¨æ¨¡å‹é€²è¡Œé£Ÿç‰©è¾¨è­˜ï¼Œä¸¦ä»¥éš¨æ©Ÿé †åºè¿”å›çµæœ
    Args:
        image: è¼¸å…¥åœ–ç‰‡
    Returns:
        åŒ…å«æ‰€æœ‰æ¨¡å‹è¾¨è­˜çµæœçš„å­—å…¸
    """
    if image is None:
        return {"éŒ¯èª¤": "è«‹ä¸Šå‚³é£Ÿç‰©åœ–ç‰‡"}
    
    # å®šç¾©æ‰€æœ‰å¯ç”¨çš„æ¨¡å‹
    available_models = [
        "convnext_90",
        "densenet_86", 
        "efficientnet_84",
        "resnet50_78",
        "swin_model_94",
        "swinv2_model_94",
        "vgg_model_78",
        "vit_model_74"
    ]
    
    # éš¨æ©Ÿæ‰“äº‚æ¨¡å‹é †åº
    shuffled_models = available_models.copy()
    random.shuffle(shuffled_models)
    
    results = {}
    results["ğŸ¯ ç¶œåˆè¾¨è­˜çµæœ"] = {}
    results["ğŸ“Š å„æ¨¡å‹è©³ç´°çµæœ"] = {}
    
    # ç”¨æ–¼çµ±è¨ˆæœ€çµ‚çµæœ
    food_votes = {}
    successful_results = []
    
    for i, model_name in enumerate(shuffled_models, 1):
        try:
            print(f"æ­£åœ¨ä½¿ç”¨æ¨¡å‹ {model_name} é€²è¡Œè¾¨è­˜...")
            result = classify_food_image(image, model_name)
            
            if "éŒ¯èª¤" not in result:
                # æˆåŠŸçš„è¾¨è­˜çµæœ
                recognized_food = result["è¾¨è­˜é£Ÿç‰©"]
                
                # çµ±è¨ˆæŠ•ç¥¨
                if recognized_food in food_votes:
                    food_votes[recognized_food] += 1
                else:
                    food_votes[recognized_food] = 1
                
                successful_results.append(result)
                
                # æ·»åŠ åˆ°è©³ç´°çµæœä¸­
                results["ğŸ“Š å„æ¨¡å‹è©³ç´°çµæœ"][f"#{i} {model_name}"] = {
                    "è¾¨è­˜é£Ÿç‰©": recognized_food,
                    "è‹±æ–‡å": result.get("è‹±æ–‡å", "unknown"),
                    "äº”æ€§å±¬æ€§": result.get("äº”æ€§å±¬æ€§", "æœªçŸ¥"),
                    "ä¿¡å¿ƒåº¦": result.get("ä¿¡å¿ƒåº¦", "N/A")
                }
            else:
                # å¤±æ•—çš„è¾¨è­˜çµæœ
                results["ğŸ“Š å„æ¨¡å‹è©³ç´°çµæœ"][f"#{i} {model_name}"] = {
                    "ç‹€æ…‹": "è¼‰å…¥å¤±æ•—",
                    "éŒ¯èª¤ä¿¡æ¯": result.get("éŒ¯èª¤", "æœªçŸ¥éŒ¯èª¤")
                }
                
        except Exception as e:
            results["ğŸ“Š å„æ¨¡å‹è©³ç´°çµæœ"][f"#{i} {model_name}"] = {
                "ç‹€æ…‹": "è¾¨è­˜å¤±æ•—", 
                "éŒ¯èª¤ä¿¡æ¯": str(e)
            }
    
    # ç”Ÿæˆç¶œåˆçµæœ
    if food_votes:
        # æ‰¾å‡ºå¾—ç¥¨æœ€å¤šçš„é£Ÿç‰©
        most_voted_food = max(food_votes, key=food_votes.get)
        vote_count = food_votes[most_voted_food]
        total_successful = len(successful_results)
        
        # ç²å–è©²é£Ÿç‰©çš„è©³ç´°è³‡è¨Š
        food_info = None
        for result in successful_results:
            if result["è¾¨è­˜é£Ÿç‰©"] == most_voted_food:
                food_info = result
                break
        
        if food_info:
            results["ğŸ¯ ç¶œåˆè¾¨è­˜çµæœ"] = {
                "æœ€çµ‚è¾¨è­˜": most_voted_food,
                "è‹±æ–‡å": food_info.get("è‹±æ–‡å", "unknown"),
                "äº”æ€§å±¬æ€§": food_info.get("äº”æ€§å±¬æ€§", "æœªçŸ¥"),
                "æ¨¡å‹å…±è­˜åº¦": f"{vote_count}/{total_successful} ({vote_count/total_successful*100:.1f}%)",
                "æˆåŠŸæ¨¡å‹æ•¸": f"{total_successful}/{len(available_models)}",
                "æŠ•ç¥¨åˆ†ä½ˆ": food_votes
            }
        else:
            results["ğŸ¯ ç¶œåˆè¾¨è­˜çµæœ"]["éŒ¯èª¤"] = "ç„¡æ³•ç²å–é£Ÿç‰©è©³ç´°è³‡è¨Š"
    else:
        results["ğŸ¯ ç¶œåˆè¾¨è­˜çµæœ"]["éŒ¯èª¤"] = "æ‰€æœ‰æ¨¡å‹éƒ½ç„¡æ³•æˆåŠŸè¾¨è­˜åœ–ç‰‡"
    
    return results

def build_food_recognition_page():
    """å»ºç«‹é£Ÿç‰©è¾¨è­˜é é¢"""
    # æ·»åŠ é£Ÿç‰©è¾¨è­˜é é¢å°ˆç”¨CSSæ¨£å¼
    food_page_css = """
    <style>
    /* === é£Ÿç‰©è¾¨è­˜é é¢å°ˆç”¨æ¨£å¼ä¿®å¾©ç‰ˆ === */
    
    /* å®¹å™¨åŸºç¤æ¨£å¼ */
    .food-recognition-container {
        background: linear-gradient(135deg, #F0F8FF 0%, #E6F3E6 25%, #FFF8F0 75%, #F0F8FF 100%) !important;
        min-height: 100vh !important;
        padding: 20px !important;
        margin: 0 !important;
        font-family: 'Microsoft YaHei', 'PingFang SC', 'Hiragino Sans GB', sans-serif !important;
    }
      /* ä¸»æ¨™é¡Œå€åŸŸ */
    .food-hero-section {
        text-align: center !important;
        padding: 20px 20px 30px 20px !important;
        background: linear-gradient(135deg, rgba(106, 153, 78, 0.05) 0%, rgba(212, 175, 55, 0.03) 100%) !important;
        border-radius: 25px !important;
        margin-bottom: 30px !important;
        border: 2px solid rgba(106, 153, 78, 0.1) !important;
        box-shadow: 0 15px 40px rgba(0, 0, 0, 0.08) !important;
        position: relative !important;
        overflow: hidden !important;
    }

    /* æ¨™é¡Œå€åŸŸé ‚éƒ¨å®¹å™¨ */
    .food-hero-header {
        display: flex !important;
        justify-content: space-between !important;
        align-items: flex-start !important;
        width: 100% !important;
        margin-bottom: 20px !important;
    }

    /* æ¨™é¡Œå…§å®¹å€åŸŸ */
    .food-hero-content {
        flex: 1 !important;
        text-align: center !important;
    }

    /* å³ä¸Šè§’æŒ‰éˆ•å€åŸŸ */
    .food-hero-button-area {
        flex-shrink: 0 !important;
        align-self: flex-start !important;
    }
    
    .food-page-title {
        color: #2D5016 !important;
        font-size: 3rem !important;
        font-weight: 700 !important;
        margin-bottom: 15px !important;
        text-shadow: 0 4px 8px rgba(0, 0, 0, 0.1) !important;
    }
    
    .food-page-subtitle {
        color: #4A6741 !important;
        font-size: 1.2rem !important;
        font-weight: 500 !important;
        line-height: 1.7 !important;
        max-width: 700px !important;
        margin: 0 auto !important;
    }
    
    /* åŠŸèƒ½å¡ç‰‡è¡Œ */
    .food-feature-cards-row {
        margin: 20px 0 !important;
        gap: 15px !important;
    }
    
    /* åŠŸèƒ½å¡ç‰‡ */
    .food-feature-card {
        background: #FEFCF8 !important;
        border-radius: 20px !important;
        padding: 20px 15px !important;
        margin: 0 !important;
        box-shadow: 0 12px 40px rgba(139, 69, 19, 0.12) !important;
        border: 2px solid rgba(212, 175, 55, 0.2) !important;
        transition: all 0.4s cubic-bezier(0.165, 0.84, 0.44, 1) !important;
        position: relative !important;
        overflow: hidden !important;
        min-height: 100px !important;
        display: flex !important;
        flex-direction: column !important;
        text-align: center !important;
    }
    
    .food-feature-card:hover {
        transform: translateY(-6px) !important;
        box-shadow: 0 20px 50px rgba(139, 69, 19, 0.18) !important;
        border-color: rgba(212, 175, 55, 0.4) !important;
    }
    
    .food-feature-icon {
        font-size: 2.5rem !important;
        margin-bottom: 8px !important;
        display: block !important;
    }
    
    .food-feature-title {
        color: #2D5016 !important;
        font-size: 1.3rem !important;
        font-weight: 600 !important;
        margin: 8px 0 5px 0 !important;
    }
    
    .food-feature-description {
        color: #4A6741 !important;
        font-size: 0.9rem !important;
        line-height: 1.5 !important;
        margin: 0 !important;
    }
    
    /* ä¸Šå‚³å€åŸŸæ¨£å¼ */
    .food-upload-section {
        background: #F0F7F0 !important;
        border-radius: 20px !important;
        padding: 20px !important;
        margin: 20px 0 !important;
        border: 2px solid rgba(106, 153, 78, 0.3) !important;
        box-shadow: 0 8px 30px rgba(106, 153, 78, 0.1) !important;
    }
      .food-upload-section h3 {
        color: #2D5016 !important;
        font-size: 1.5rem !important;
        font-weight: 600 !important;
        margin-bottom: 15px !important;
        text-align: center !important;
    }
    
    /* æŒ‰éˆ•æ¨£å¼ */
    .food-recognition-btn {
        background: linear-gradient(135deg, #6A9A4E 0%, #5A8A3E 100%) !important;
        color: white !important;
        border: none !important;
        border-radius: 12px !important;
        padding: 12px 20px !important;
        font-size: 1.1rem !important;
        font-weight: 600 !important;
        transition: all 0.3s ease !important;
        box-shadow: 0 6px 20px rgba(106, 154, 78, 0.3) !important;
        margin: 8px 0 !important;
        min-width: 200px !important;
        cursor: pointer !important;
    }
    
    .food-recognition-btn:hover {
        transform: translateY(-3px) !important;
        box-shadow: 0 12px 35px rgba(106, 154, 78, 0.4) !important;
        background: linear-gradient(135deg, #5A8A3E 0%, #4A7A2E 100%) !important;
    }
    
    /* æ¼‚æµ®è¿”å›æŒ‰éˆ•æ¨£å¼ - ä½¿ç”¨ app.py çš„çµ±ä¸€æ¨£å¼ */
    
    /* çµæœé¡¯ç¤ºå€åŸŸ */
    .food-result-section {
        background: linear-gradient(135deg, #F8FBF6 0%, #FEFEFE 100%) !important;
        border-radius: 20px !important;
        padding: 20px !important;
        margin: 20px 0 !important;
        border: 2px solid rgba(106, 153, 78, 0.2) !important;
        box-shadow: 0 15px 40px rgba(106, 153, 78, 0.15) !important;
        position: relative !important;
    }
    
    /* ç‹€æ…‹é¡¯ç¤º */
    .status-display {
        background: linear-gradient(135deg, #E8F5E8 0%, #F0F8F0 100%) !important;
        border: 2px solid rgba(106, 153, 78, 0.3) !important;
        border-radius: 12px !important;
        padding: 15px 20px !important;
        color: #2D5016 !important;
        font-weight: 600 !important;
        text-align: center !important;
        margin: 15px 0 !important;
        font-size: 1rem !important;
    }
    
    /* === ä¿®å¾© Gradio çµ„ä»¶é¡è‰²å•é¡Œ === */
    
    /* å…¨å±€æ–‡å­—é¡è‰²ä¿®å¾© */
    .gradio-container * {
        color: #2D5016 !important;
    }
    
    /* æ¨™ç±¤æ–‡å­—ä¿®å¾© */
    .gradio-container label,
    .gradio-container .gr-form label,
    .gradio-container .gr-block-label,
    .gradio-container .gr-block-title,
    .gradio-container .label-wrap,
    .gradio-container .label-wrap span {
        color: #2D5016 !important;
        font-weight: 600 !important;
        background-color: transparent !important;
        font-size: 14px !important;
    }
    
    /* è¼¸å…¥æ¡†å’Œæ–‡å­—å€åŸŸä¿®å¾© */
    .gradio-container input,
    .gradio-container textarea,
    .gradio-container select,
    .gradio-container .gr-textbox,
    .gradio-container .gr-textbox textarea,
    .gradio-container .gr-text-input {
        color: #2D5016 !important;
        background-color: #FFFFFF !important;
        border: 2px solid rgba(106, 153, 78, 0.3) !important;
        font-size: 14px !important;
        line-height: 1.5 !important;
        padding: 8px 12px !important;
    }
    
    /* ä¸‹æ‹‰é¸å–®ä¿®å¾© */
    .gradio-container .gr-dropdown,
    .gradio-container .gr-dropdown div,
    .gradio-container .gr-dropdown span,
    .gradio-container .gr-dropdown .wrap,
    .gradio-container .gr-dropdown .secondary-wrap {
        color: #2D5016 !important;
        background-color: #FFFFFF !important;
        border: 2px solid rgba(106, 153, 78, 0.3) !important;
    }
    
    /* ä¸‹æ‹‰é¸å–®ä¿®å¾© - å¼·åŒ–ç‰ˆ */
    .gradio-container select,
    .gradio-container .gr-dropdown,
    .gradio-container .dropdown,
    .gradio-container [data-testid="dropdown"],
    .gradio-container .gradio-dropdown,
    .gradio-container .gr-form .gr-dropdown,
    .gradio-container .select-wrap,
    .gradio-container .select-wrap select,
    .gradio-container .gr-form select {
        color: #2D5016 !important;
        background-color: #FFFFFF !important;
        border: 2px solid rgba(106, 153, 78, 0.3) !important;
        font-size: 14px !important;
        font-weight: 500 !important;
        padding: 8px 12px !important;
        height: auto !important;
        opacity: 1 !important;
        visibility: visible !important;
        pointer-events: auto !important;
    }
    
    /* ä¸‹æ‹‰é¸å–®é¸é …ä¿®å¾© */
    .gradio-container .gr-dropdown option,
    .gradio-container select option,
    .gradio-container .select-wrap option,
    .gradio-container .dropdown option,
    .gradio-container [data-testid="dropdown"] option {
        color: #2D5016 !important;
        background-color: #FFFFFF !important;
        font-size: 14px !important;
        padding: 8px !important;
    }
    
    /* ä¸‹æ‹‰é¸å–®äº’å‹•ç‹€æ…‹ */
    .gradio-container .gr-dropdown:hover,
    .gradio-container .gr-dropdown:focus,
    .gradio-container .gr-dropdown:active,
    .gradio-container select:hover,
    .gradio-container select:focus,
    .gradio-container select:active {
        border-color: rgba(106, 153, 78, 0.6) !important;
        box-shadow: 0 0 0 2px rgba(106, 153, 78, 0.2) !important;
    }
    
    /* æŒ‰éˆ•æ–‡å­—ç¢ºä¿ç‚ºç™½è‰² */
    .gradio-container button,
    .gradio-container button span,
    .gradio-container .gr-button,
    .gradio-container .gr-button span {
        color: white !important;
        font-weight: 600 !important;
    }    /* Tab æ¨™ç±¤ä¿®å¾© - ä½¿ç”¨æ›´å¼·çš„é¸æ“‡å™¨ */
    .gradio-container .tabitem button,
    .gradio-container .tab-nav button,
    .gradio-container button[role="tab"],
    .gradio-container .gr-tab-nav button,
    .gradio-container .gr-tab-nav button span,
    .gradio-container .tab-nav button span,
    .gradio-container button[role="tab"] span {
        background-color: #466235 !important; /* æ·±ç¶ è‰²èƒŒæ™¯ */
        color: #FFFFFF !important;
        font-weight: 600 !important;
        border: 2px solid rgba(106, 153, 78, 0.2) !important;
        border-radius: 8px !important;
        margin: 2px !important;
        padding: 12px 16px !important;
        font-size: 14px !important;
        transition: all 0.3s ease !important;
    }
    
    .gradio-container .tabitem button:hover,
    .gradio-container .tab-nav button:hover,
    .gradio-container button[role="tab"]:hover,
    .gradio-container .gr-tab-nav button:hover,
    .gradio-container .tabitem button:hover span,
    .gradio-container .tab-nav button:hover span,
    .gradio-container button[role="tab"]:hover span {
        background-color: #3A522C !important; /* æ›´æ·±çš„ç¶ è‰² */
        color: #FFFFFF !important;
        border-color: rgba(106, 153, 78, 0.4) !important;
    }
    
    .gradio-container .tabitem button.selected,
    .gradio-container .tab-nav button.selected,
    .gradio-container button[role="tab"][aria-selected="true"],
    .gradio-container .gr-tab-nav button.selected,
    .gradio-container .gr-tab-nav button[aria-selected="true"],
    .gradio-container .tabitem button.selected span,
    .gradio-container .tab-nav button.selected span,
    .gradio-container button[role="tab"][aria-selected="true"] span {
        background-color: #2D4017 !important; /* éå¸¸æ·±çš„ç¶ è‰² */
        color: #FFFFFF !important;
        box-shadow: 0 4px 12px rgba(0, 0, 0, 0.3) !important;
        border-color: #6A9A4E !important;
    }/* å¼·åˆ¶è¦†è“‹æ‰€æœ‰å¯èƒ½çš„Tabæ–‡å­—é¡è‰² */
    .gradio-container [role="tablist"] button,
    .gradio-container [role="tablist"] button *,
    .gradio-container .tabs button,
    .gradio-container .tabs button *,
    .gradio-container div[role="tablist"] button,
    .gradio-container div[role="tablist"] button * {
        color: #FFFFFF !important;
    }
    
    /* é€šç”¨TabæŒ‰éˆ•å¼·åˆ¶ç™½è‰²æ–‡å­— */
    .gradio-container button[role="tab"],
    .gradio-container button[role="tab"] *,
    .gradio-container [data-testid="tab"],
    .gradio-container [data-testid="tab"] *,
    .gradio-container .tab-nav button,
    .gradio-container .tab-nav button *,
    .gradio-container .gr-tab-nav button,
    .gradio-container .gr-tab-nav button * {
        color: #FFFFFF !important;
        text-shadow: none !important;
    }      /* æœ€å¼·åŠ›çš„è¦†è“‹ - é‡å°ä»»ä½•åŒ…å«æ¨™ç±¤emojiçš„æŒ‰éˆ• */
    .gradio-container button:contains("ğŸ¯"),
    .gradio-container button:contains("ğŸ“Š"), 
    .gradio-container button:contains("ğŸ”") {
        color: #FFFFFF !important;
    }
    
    /* çµ‚æ¥µTabæ–‡å­—é¡è‰²ä¿®å¾© - é‡å°Gradioå‹•æ…‹ç”Ÿæˆçš„å…ƒç´  */
    .gradio-container button,
    .gradio-container button span,
    .gradio-container [role="tab"],
    .gradio-container [role="tab"] span,
    .gradio-container [data-testid*="tab"],
    .gradio-container [data-testid*="tab"] span,
    .gradio-container .tab-item,
    .gradio-container .tab-item span,
    .gradio-container .tabitem,
    .gradio-container .tabitem span {
        color: #FFFFFF !important;
    }
      /* é‡å°å¯èƒ½çš„æ·±è‰²æ–‡å­—è¦†è“‹ */
    .gradio-container button:not([class*="food-recognition"]):not([class*="single-model"]) {
        color: #FFFFFF !important;
    }
    
    .gradio-container button:not([class*="food-recognition"]):not([class*="single-model"]) span {
        color: #FFFFFF !important;
    }
    
    /* ç‰¹åˆ¥é‡å°TabæŒ‰éˆ•çš„å¼·åˆ¶ç™½è‰²æ–‡å­— */
    .gradio-container [role="tablist"] button[role="tab"],
    .gradio-container [role="tablist"] button[role="tab"] *,
    .gradio-container .tabs .tab-nav button,
    .gradio-container .tabs .tab-nav button *,
    .gradio-container .gr-tabs button,
    .gradio-container .gr-tabs button * {
        color: #FFFFFF !important;
        text-shadow: 0 1px 2px rgba(0,0,0,0.3) !important;
    }
    
    /* çµæœé¡¯ç¤ºå€åŸŸæ–‡å­—ä¿®å¾© */
    .gradio-container .json-holder,
    .gradio-container .json-holder *,
    .gradio-container .recognition-container,
    .gradio-container .recognition-container *,
    .gradio-container .recognition-container textarea {
        color: #2D5016 !important;
        background-color: #FFFFFF !important;
        border: 2px solid rgba(106, 153, 78, 0.2) !important;
        font-family: 'Microsoft YaHei', 'Segoe UI', sans-serif !important;
        font-size: 14px !important;
        line-height: 1.6 !important;
        padding: 15px !important;
    }
    
    /* Tab å…§å®¹å€åŸŸä¿®å¾© */
    .gradio-container .gr-tab-item,
    .gradio-container .gr-tab-item *,
    .gradio-container .gr-tab-item div,
    .gradio-container .gr-tab-item span {
        color: #2D5016 !important;
        background-color: transparent !important;
    }
    
    /* åœ–ç‰‡ä¸Šå‚³å€åŸŸä¿®å¾© */
    .gradio-container .gr-image,
    .gradio-container .gr-image *,
    .gradio-container .gr-file-upload,
    .gradio-container .gr-file-upload * {
        color: #2D5016 !important;
        border: 2px solid rgba(106, 153, 78, 0.3) !important;
        border-radius: 12px !important;
    }
    
    /* Tab èªªæ˜å€åŸŸ */
    .tab-description {
        background: rgba(106, 153, 78, 0.1) !important;
        border-radius: 10px !important;
        padding: 15px 20px !important;
        margin-bottom: 20px !important;
        border-left: 4px solid #6A9A4E !important;
        color: #2D5016 !important;
    }
    
    .tab-description strong {
        color: #2D5016 !important;
        font-size: 1.1rem !important;
        font-weight: 700 !important;
    }
    
    /* éŸ¿æ‡‰å¼è¨­è¨ˆ */
    @media (max-width: 768px) {
        .food-feature-cards-row {
            flex-direction: column !important;
        }
        
        .food-feature-card {
            margin: 10px 0 !important;
        }
        
        .food-page-title {
            font-size: 2.2rem !important;
        }
        
        .food-recognition-container {
            padding: 15px !important;
            margin: 5px !important;
        }
    }
    
    /* ä¿®å¾©ä¸‹æ‹‰é¸å–® - æœ€æ–°ç‰ˆGradioå…¼å®¹ */
    div.gradio-dropdown {
        display: block !important;
        visibility: visible !important;
        opacity: 1 !important;
        background-color: white !important;
        color: #2D5016 !important;
        border: 2px solid rgba(106, 153, 78, 0.3) !important;
        border-radius: 8px !important;
        position: relative !important;
        z-index: 100 !important;
        width: 100% !important;
    }
    
    /* å¼·åˆ¶é¡¯ç¤ºä¸‹æ‹‰é¸å–®çš„é¸é … */
    div.gradio-dropdown > ul,
    div.gradio-dropdown div[role="listbox"],
    div.gradio-dropdown div[class*="list-container"] {
        display: block !important;
        visibility: visible !important;
        opacity: 1 !important;
        background-color: white !important;
        color: #2D5016 !important;
        border-radius: 8px !important;
        z-index: 101 !important;
        box-shadow: 0 4px 15px rgba(0, 0, 0, 0.1) !important;
    }
    
    /* ä¸‹æ‹‰ç®­é ­æŒ‰éˆ• */
    div.gradio-dropdown button[aria-label="Show options"],
    div.gradio-dropdown button[class*="arrow"] {
        visibility: visible !important;
        opacity: 1 !important;
        color: #2D5016 !important;
    }
    
    /* ä¸‹æ‹‰é¸å–®é …ç›® */
    div.gradio-dropdown li,
    div.gradio-dropdown div[role="option"],
    div.gradio-dropdown div[class*="item"] {
        color: #2D5016 !important;
        background-color: white !important;
        padding: 8px 12px !important;
    }
    
    /* ä¸‹æ‹‰é¸å–®æ‡¸åœæ•ˆæœ */
    div.gradio-dropdown li:hover,
    div.gradio-dropdown div[role="option"]:hover,
    div.gradio-dropdown div[class*="item"]:hover {
        background-color: rgba(106, 153, 78, 0.1) !important;
    }
    
    /* ä¸‹æ‹‰é¸å–®å·²é¸ä¸­é …ç›® */
    div.gradio-dropdown li[aria-selected="true"],
    div.gradio-dropdown div[role="option"][aria-selected="true"],
    div.gradio-dropdown div[class*="item"][data-selected="true"] {
        background-color: rgba(106, 153, 78, 0.2) !important;
        font-weight: 600 !important;
    }
    
    /* ä¸‹æ‹‰é¸å–®æ–‡å­—é¡è‰² */
    div.gradio-dropdown *,
    div.gradio-dropdown span,
    div.gradio-dropdown div,
    div.gradio-dropdown p {
        color: #2D5016 !important;
    }

    /* Gradio 5.x ç‰ˆæœ¬ä¸‹æ‹‰é¸å–®ä¿®å¾© */
    .block.gr-box > div[class^="wrap"] select,
    select.svelte-selector,
    .gradio-dropdown,
    [id^="component-"] select,
    div[class*="dropdown"] select {
        display: block !important;
        visibility: visible !important;
        opacity: 1 !important;
        pointer-events: auto !important;
        z-index: 100 !important;
        color: #2D5016 !important;
        background-color: white !important;
        border: 2px solid rgba(106, 153, 78, 0.3) !important;
        border-radius: 8px !important;
        padding: 8px 12px !important;
        font-size: 14px !important;
        font-weight: 500 !important;
        width: 100% !important;
        max-width: 100% !important;
        margin: 0 !important;
        height: auto !important;
        min-height: 40px !important;
    }

    /* Gradio 5.x æ»‘é¼ æ‡¸åœèˆ‡ç„¦é»æ•ˆæœ */
    .block.gr-box > div[class^="wrap"] select:hover,
    select.svelte-selector:hover,
    .gradio-dropdown:hover,
    [id^="component-"] select:hover,
    div[class*="dropdown"] select:hover,
    .block.gr-box > div[class^="wrap"] select:focus,
    select.svelte-selector:focus,
    .gradio-dropdown:focus,
    [id^="component-"] select:focus,
    div[class*="dropdown"] select:focus {
        border-color: rgba(106, 153, 78, 0.6) !important;
        box-shadow: 0 0 0 2px rgba(106, 153, 78, 0.2) !important;
        outline: none !important;
    }

    /* Gradio 5.x é¸é …æ¨£å¼ */
    .block.gr-box > div[class^="wrap"] select option,
    select.svelte-selector option,
    .gradio-dropdown option,
    [id^="component-"] select option,
    div[class*="dropdown"] select option {
        color: #2D5016 !important;
        background-color: white !important;
        padding: 8px !important;
        font-size: 14px !important;
    }

    /* ç¢ºä¿ä¸‹æ‹‰é¸å–®é»æ“Šäº‹ä»¶ */
    .gradio-container {
        --dropdown-background-color: white !important;
        --dropdown-text-color: #2D5016 !important;
        --dropdown-border-color: rgba(106, 153, 78, 0.3) !important;
    }

    /* ä¿®å¾©ä¸‹æ‹‰é¸å–®çš„é»æ“Šå’Œé¡¯ç¤ºå•é¡Œ */
    .gradio-container [data-testid="dropdown"],
    .gradio-container [data-testid="dropdown"] *,
    .gradio-container select,
    .gradio-container .select-wrap,
    .gradio-container .gr-dropdown {
        pointer-events: auto !important;
        user-select: auto !important;
        -webkit-user-select: auto !important;
        cursor: pointer !important;
    }

    /* é¿å…ä¸‹æ‹‰é¸å–®è¢«å…¶ä»–å…ƒç´ è¦†è“‹ */
    .gradio-container [data-testid="dropdown"]:focus,
    .gradio-container [data-testid="dropdown"]:active,
    .gradio-container select:focus,
    .gradio-container select:active,
    .gradio-container .select-wrap:focus,
    .gradio-container .select-wrap:active {
        z-index: 1000 !important;
        position: relative !important;
    }
    
    /* å¼·åˆ¶é¡¯ç¤ºä¸‹æ‹‰ç®­é ­ */
    .gradio-container [data-testid="dropdown"] svg,
    .gradio-container [data-testid="dropdown"] [data-testid="arrow"],
    .gradio-container .select-wrap svg,
    .gradio-container .select-wrap [data-testid="arrow"] {
        display: block !important;
        visibility: visible !important;
        opacity: 1 !important;
        color: #2D5016 !important;
    }

    /* ç‰¹å®šå„ªåŒ–ä¸‹æ‹‰é¸å–®æ¨£å¼ */
    #model_selector, 
    div[id^="component-"] select,
    .gr-dropdown[id="model_selector"] {
        display: block !important;
        width: 100% !important;
        height: auto !important;
        min-height: 45px !important;
        background-color: white !important;
        color: #2D5016 !important;
        border: 2px solid #6A9A4E !important;
        border-radius: 10px !important;
        padding: 10px 15px !important;
        font-size: 16px !important;
        font-weight: 500 !important;
        box-shadow: 0 4px 10px rgba(106, 153, 78, 0.2) !important;
        margin: 8px 0 !important;
        transition: all 0.3s ease !important;
        cursor: pointer !important;
        position: relative !important;
        z-index: 50 !important;
    }
    
    #model_selector:hover,
    div[id^="component-"] select:hover,
    .gr-dropdown[id="model_selector"]:hover {
        border-color: #5A8A3E !important;
        box-shadow: 0 6px 15px rgba(106, 153, 78, 0.3) !important;
        transform: translateY(-2px) !important;
    }
    
    #model_selector:focus,
    div[id^="component-"] select:focus,
    .gr-dropdown[id="model_selector"]:focus {
        outline: none !important;
        border-color: #4A7A2E !important;
        box-shadow: 0 0 0 3px rgba(106, 153, 78, 0.3) !important;
    }

    /* ä¸‹æ‹‰é¸å–®æ¨£å¼å„ªåŒ– */
    .gradio-container .model-dropdown,
    #model_selector,
    .gradio-container #model_selector,
    .gradio-container [data-testid="dropdown"],
    .gr-dropdown[id="model_selector"] {
        display: block !important;
        width: 100% !important;
        height: auto !important;
        min-height: 45px !important;
        background-color: white !important;
        color: #2D5016 !important;
        border: 2px solid #6A9A4E !important;
        border-radius: 10px !important;
        padding: 10px 15px !important;
        font-size: 16px !important;
        font-weight: 500 !important;
        box-shadow: 0 4px 10px rgba(106, 153, 78, 0.2) !important;
        margin: 8px 0 !important;
        transition: all 0.3s ease !important;
        cursor: pointer !important;
        position: relative !important;
        z-index: 50 !important;
    }
    
    .gradio-container .model-dropdown:hover,
    #model_selector:hover,
    .gr-dropdown[id="model_selector"]:hover {
        border-color: #5A8A3E !important;
        box-shadow: 0 6px 15px rgba(106, 153, 78, 0.3) !important;
        transform: translateY(-2px) !important;
    }
    
    .gradio-container .model-dropdown:focus,
    #model_selector:focus,
    .gr-dropdown[id="model_selector"]:focus {
        outline: none !important;
        border-color: #4A7A2E !important;
        box-shadow: 0 0 0 3px rgba(106, 153, 78, 0.3) !important;
    }

    /* ä¸‹æ‹‰é¸å–®é¸é …æ¨£å¼ */
    .gradio-container .model-dropdown .option,
    #model_selector .option,
    .gr-dropdown[id="model_selector"] .option {
        color: #2D5016 !important;
        background-color: white !important;
        padding: 10px 15px !important;
        border-bottom: 1px solid rgba(106, 153, 78, 0.1) !important;
        cursor: pointer !important;
        transition: all 0.2s ease !important;
    }
    
    .gradio-container .model-dropdown .option:hover,
    #model_selector .option:hover,
    .gr-dropdown[id="model_selector"] .option:hover {
        background-color: rgba(106, 153, 78, 0.1) !important;
        color: #2D5016 !important;
    }
    
    .gradio-container .model-dropdown .option:selected,
    .gradio-container .model-dropdown .option[aria-selected="true"],
    #model_selector .option:selected,
    .gr-dropdown[id="model_selector"] .option[aria-selected="true"] {
        background-color: #6A9A4E !important;
        color: white !important;
        font-weight: 600 !important;
    }
        box-sizing: border-box !important;
    }
    </style>
    """
    
    # ä¸å†éœ€è¦é¡å¤–çš„æ¼‚æµ®æŒ‰éˆ•ï¼Œä½¿ç”¨ app.py ä¸­çš„çµ±ä¸€æŒ‰éˆ•
    with gr.Column(elem_classes=["food-recognition-container"]):        # æ·»åŠ CSSæ¨£å¼
        gr.HTML(food_page_css)
        
        # è‹±é›„å€åŸŸ - é é¢æ¨™é¡Œå’Œèªªæ˜
        with gr.Column(elem_classes=["food-hero-section"]):
            gr.HTML("""
                <div style="margin-top: 40px;">
                    <h1 class="food-page-title">AIé£Ÿç‰©è¾¨è­˜æ¨¡çµ„</h1>
                    <p class="food-page-subtitle">
                        é‹ç”¨æ·±åº¦å­¸ç¿’æŠ€è¡“è¾¨è­˜é£Ÿç‰©ï¼Œæä¾›ä¸­é†«äº”æ€§å±¬æ€§åˆ†æï¼ŒåŠ©æ‚¨äº†è§£é£Ÿç‰©çš„å¯’ç†±ç‰¹æ€§
                    </p>
                </div>
            """)
        
        # åŠŸèƒ½ç‰¹è‰²èªªæ˜ - ä½¿ç”¨å¡ç‰‡å½¢å¼
        with gr.Row(elem_classes=["food-feature-cards-row"]):
            with gr.Column(elem_classes=["food-feature-card"]):
                gr.HTML("""
                <div class="food-feature-icon">ğŸ¯</div>
                <h4 class="food-feature-title">å¤šæ¨¡å‹æŠ•ç¥¨</h4>
                <p class="food-feature-description">8å€‹AIæ¨¡å‹å”åŒåˆ¤æ–·ï¼Œæå‡è¾¨è­˜æº–ç¢ºåº¦</p>
                """)
            
            with gr.Column(elem_classes=["food-feature-card"]):
                gr.HTML("""
                <div class="food-feature-icon">ğŸ”¬</div>
                <h4 class="food-feature-title">æ·±åº¦å­¸ç¿’</h4>
                <p class="food-feature-description">æœ€æ–°Transformeræ¶æ§‹ï¼Œç²¾æº–è­˜åˆ¥é£Ÿç‰©</p>
                """)
            
            with gr.Column(elem_classes=["food-feature-card"]):
                gr.HTML("""
                <div class="food-feature-icon">ğŸŒ¡ï¸</div>
                <h4 class="food-feature-title">ä¸­é†«å±¬æ€§</h4>
                <p class="food-feature-description">æä¾›é£Ÿç‰©äº”æ€§å¯’ç†±åˆ†æï¼Œèåˆå‚³çµ±æ™ºæ…§</p>
                """)
            
            # ä¸Šå‚³å€åŸŸ
        with gr.Column(elem_classes=["food-upload-section"]):
            gr.HTML("<h3>ğŸ“¸ ä¸Šå‚³é£Ÿç‰©åœ–ç‰‡</h3>")
            
            with gr.Row():
                with gr.Column():
                    food_image = gr.Image(
                        label="é¸æ“‡æˆ–æ‹–æ‹½é£Ÿç‰©åœ–ç‰‡", 
                        type="pil",
                        height=400,
                        container=True
                    )
                
                with gr.Column():
                    # æ¨¡å‹é¸æ“‡å€åŸŸ
                    gr.HTML("""
                    <div style="background: rgba(106, 153, 78, 0.1); padding: 15px; border-radius: 10px; margin: 15px 0;">
                        <h4 style="color: #4A6741; margin-bottom: 10px;">ğŸ¤– AIæ¨¡å‹èªªæ˜</h4>
                        <p style="color: #6A9A4E; font-size: 0.9rem; margin: 0;">
                            ç³»çµ±å°‡è‡ªå‹•ä½¿ç”¨å¤šå€‹AIæ¨¡å‹é€²è¡Œç¶œåˆè¾¨è­˜ï¼Œä»¥æé«˜æº–ç¢ºæ€§ã€‚
                        </p>
                    </div>
                    """)
                    
                    # è¾¨è­˜æŒ‰éˆ•
                    recognize_all_btn = gr.Button(
                        "ğŸ¯ å¤šæ¨¡å‹ç¶œåˆè¾¨è­˜",
                        elem_classes=["food-recognition-btn"],
                        variant="primary",
                        size="lg"
                    )
                    
                    # single_model_btn = gr.Button(
                    #     "ğŸ” å–®ä¸€æ¨¡å‹è¾¨è­˜", 
                    #     elem_classes=["food-single-model-btn"],
                    #     variant="secondary",
                    #     size="lg"
                    # )

            # ç¯„ä¾‹åœ–ç‰‡é¸æ“‡å€åŸŸ
            with gr.Column(elem_classes=["food-upload-section"]):
                gr.HTML("<h3>ğŸ–¼ï¸ æˆ–é¸æ“‡ç¯„ä¾‹åœ–ç‰‡è©¦è©¦çœ‹</h3>")
                
                with gr.Row():
                    # å®šç¾©ç¯„ä¾‹åœ–ç‰‡ä¿¡æ¯
                    sample_images = [
                        {"name": "é®‘é­š", "file": "Abalone.jpg", "desc": "æµ·é®®é¡"},
                        {"name": "ç«¹ç­", "file": "Bambooshoot.jpg", "desc": "è”¬èœé¡"},
                        {"name": "ç‰ç±³", "file": "Corn.jpg", "desc": "ç©€ç‰©é¡"},
                        {"name": "æ¯›è±†", "file": "GreenSoybean.jpg", "desc": "è±†é¡"},
                        {"name": "èœ‚èœœ", "file": "Honey.jpg", "desc": "ç”œå“é¡"},
                        {"name": "é¦¬éˆ´è–¯", "file": "Potato.jpg", "desc": "æ ¹è–é¡"},
                        {"name": "æ¥Šæ¡ƒ", "file": "Starfruit.jpg", "desc": "æ°´æœé¡"},
                        {"name": "é´¨æ¢¨", "file": "Yapear.jpg", "desc": "æ°´æœé¡"}
                    ]
                    
                    # å‰µå»ºç¯„ä¾‹åœ–ç‰‡æŒ‰éˆ•
                    sample_buttons = []
                    for i, img_info in enumerate(sample_images):
                        with gr.Column(scale=1):
                            btn = gr.Button(
                                f"ğŸ½ï¸ {img_info['name']}\n({img_info['desc']})",
                                elem_classes=["food-recognition-btn"],
                                variant="secondary",
                                size="sm"
                            )
                            sample_buttons.append((btn, img_info['file']))
        
        # ç‹€æ…‹é¡¯ç¤º
        status_display = gr.Textbox(
            label="ğŸ“Š è¾¨è­˜ç‹€æ…‹",
            value="è«‹ä¸Šå‚³é£Ÿç‰©åœ–ç‰‡é–‹å§‹è¾¨è­˜",
            interactive=False,
            container=True,
            elem_classes=["status-display"],
            lines=1,
            max_lines=1
        )
          # çµæœé¡¯ç¤ºå€åŸŸ
        with gr.Column(elem_classes=["food-result-section"]):
            gr.HTML("<h3 style='color: #4A6741; text-align: center; margin-bottom: 20px;'>ğŸ“‹ è¾¨è­˜çµæœ</h3>")
            
            with gr.Tabs():
                with gr.TabItem("ğŸ¯ ç¶œåˆè¾¨è­˜çµæœ", elem_id="comprehensive_tab"):
                    gr.HTML("""
                    <div class="tab-description">
                        <strong>ğŸ† å¤šæ¨¡å‹æŠ•ç¥¨çµæœ</strong><br>
                        æ•´åˆ8å€‹AIæ¨¡å‹çš„è¾¨è­˜çµæœï¼Œé€šéæŠ•ç¥¨æ©Ÿåˆ¶å¾—å‡ºæœ€çµ‚åˆ¤æ–·ï¼Œæä¾›æœ€é«˜çš„æº–ç¢ºåº¦å’Œå¯é æ€§ã€‚
                    </div>
                    """)
                    
                    comprehensive_result_display = gr.Textbox(
                        label="å¤šæ¨¡å‹ç¶œåˆè¾¨è­˜çµæœ",
                        container=True,
                        show_label=True,
                        lines=15,
                        max_lines=20,
                        elem_classes=["json-holder", "recognition-container"],
                        interactive=False
                    )
                
                with gr.TabItem("ğŸ“Š å„æ¨¡å‹è©³ç´°çµæœ", elem_id="detailed_tab"):
                    gr.HTML("""
                    <div class="tab-description">
                        <strong>ğŸ” å„æ¨¡å‹ç¨ç«‹åˆ†æ</strong><br>
                        æŸ¥çœ‹æ¯å€‹AIæ¨¡å‹ï¼ˆSwin Transformerã€Vision Transformerã€ConvNeXtã€EfficientNetã€VGGç­‰ï¼‰çš„è©³ç´°è¾¨è­˜çµæœå’Œæº–ç¢ºåº¦è©•ä¼°ã€‚
                    </div>
                    """)
                    
                    detailed_result_display = gr.Textbox(
                        label="å„æ¨¡å‹è©³ç´°è¾¨è­˜çµæœ",
                        container=True,
                        show_label=True,
                        lines=15,
                        max_lines=20,
                        elem_classes=["json-holder", "recognition-container"],
                        interactive=False
                    )
                
                # with gr.TabItem("ğŸ” å–®ä¸€æ¨¡å‹çµæœ", elem_id="single_tab"):
                #     gr.HTML("""
                #     <div class="tab-description">
                #         <strong>ğŸ¯ æŒ‡å®šæ¨¡å‹è¾¨è­˜</strong><br>
                #         ä½¿ç”¨æ‚¨åœ¨å·¦å´é¸æ“‡çš„ç‰¹å®šAIæ¨¡å‹é€²è¡Œé£Ÿç‰©è¾¨è­˜ï¼Œå¯æ¯”è¼ƒä¸åŒæ¨¡å‹çš„è¾¨è­˜èƒ½åŠ›å’Œç‰¹é»ã€‚
                #     </div>
                #     """)
                #     
                #     single_result_display = gr.Textbox(
                #         label="å–®ä¸€æ¨¡å‹è¾¨è­˜çµæœ",
                #         container=True,
                #         show_label=True,
                #         lines=15,                        max_lines=20,
                #         elem_classes=["json-holder", "recognition-container"],
                #         interactive=False
                #     )
        
        def format_comprehensive_result(result_dict):
            """æ ¼å¼åŒ–ç¶œåˆè¾¨è­˜çµæœç‚ºå¯è®€æ–‡æœ¬"""
            if not result_dict or "éŒ¯èª¤" in result_dict:
                return f"âŒ éŒ¯èª¤: {result_dict.get('éŒ¯èª¤', 'æœªçŸ¥éŒ¯èª¤')}"
            
            text = "å¤šæ¨¡å‹ç¶œåˆè¾¨è­˜çµæœ\n"
            text += "=" * 40 + "\n\n"
            
            text += f"æœ€çµ‚è¾¨è­˜: {result_dict.get('æœ€çµ‚è¾¨è­˜', 'N/A')}\n"
            text += f"è‹±æ–‡å: {result_dict.get('è‹±æ–‡å', 'N/A')}\n"
            text += f"äº”æ€§å±¬æ€§: {result_dict.get('äº”æ€§å±¬æ€§', 'N/A')}\n"
            text += f"æ¨¡å‹å…±è­˜åº¦: {result_dict.get('æ¨¡å‹å…±è­˜åº¦', 'N/A')}\n"
            text += f"æˆåŠŸæ¨¡å‹æ•¸: {result_dict.get('æˆåŠŸæ¨¡å‹æ•¸', 'N/A')}\n\n"
            
            if "æŠ•ç¥¨åˆ†ä½ˆ" in result_dict:
                text += "å„é£Ÿç‰©å¾—ç¥¨åˆ†ä½ˆ:\n"
                for food, votes in result_dict["æŠ•ç¥¨åˆ†ä½ˆ"].items():
                    text += f"   â€¢ {food}: {votes} ç¥¨\n"
            
            return text
        
        def format_detailed_result(result_dict):
            """æ ¼å¼åŒ–è©³ç´°è¾¨è­˜çµæœç‚ºå¯è®€æ–‡æœ¬"""
            if not result_dict:
                return "âŒ ç„¡è©³ç´°çµæœ"
            
            text = "å„æ¨¡å‹è©³ç´°è¾¨è­˜çµæœ\n"
            text += "=" * 40 + "\n\n"
            
            for model_key, result in result_dict.items():
                text += f"ğŸ¤– {model_key}\n"
                text += "-" * 30 + "\n"
                
                if "éŒ¯èª¤ä¿¡æ¯" in result:
                    text += f"âŒ ç‹€æ…‹: {result.get('ç‹€æ…‹', 'å¤±æ•—')}\n"
                    text += f"ğŸ’¬ éŒ¯èª¤ä¿¡æ¯: {result.get('éŒ¯èª¤ä¿¡æ¯', 'æœªçŸ¥éŒ¯èª¤')}\n"
                else:
                    text += f"è¾¨è­˜é£Ÿç‰©: {result.get('è¾¨è­˜é£Ÿç‰©', 'N/A')}\n"
                    text += f"è‹±æ–‡å: {result.get('è‹±æ–‡å', 'N/A')}\n"
                    text += f"äº”æ€§å±¬æ€§: {result.get('äº”æ€§å±¬æ€§', 'N/A')}\n"
                    text += f"ä¿¡å¿ƒåº¦: {result.get('ä¿¡å¿ƒåº¦', 'N/A')}\n"
                
                text += "\n"
            
            return text
        def format_single_result(result_dict):
            """æ ¼å¼åŒ–å–®ä¸€æ¨¡å‹çµæœç‚ºå¯è®€æ–‡æœ¬"""
            if not result_dict or "éŒ¯èª¤" in result_dict:
                return f"âŒ éŒ¯èª¤: {result_dict.get('éŒ¯èª¤', 'æœªçŸ¥éŒ¯èª¤')}"
            
            text = "ğŸ” å–®ä¸€æ¨¡å‹è¾¨è­˜çµæœ\n"
            text += "=" * 40 + "\n\n"
            
            text += f"è¾¨è­˜é£Ÿç‰©: {result_dict.get('è¾¨è­˜é£Ÿç‰©', 'N/A')}\n"
            text += f"è‹±æ–‡å: {result_dict.get('è‹±æ–‡å', 'N/A')}\n"
            text += f"äº”æ€§å±¬æ€§: {result_dict.get('äº”æ€§å±¬æ€§', 'N/A')}\n"
            text += f"ä½¿ç”¨æ¨¡å‹: {result_dict.get('ä½¿ç”¨æ¨¡å‹', 'N/A')}\n"
            text += f"ä¿¡å¿ƒåº¦: {result_dict.get('ä¿¡å¿ƒåº¦', 'N/A')}\n"
            text += f"é‹è¡Œæ¨¡å¼: {result_dict.get('æ¨¡å¼', 'N/A')}\n"
            
            return text

        def update_quick_result_on_button(image, model_name=None, use_all_models=False):
            """æŒ‰éˆ•é»æ“Šå¾Œçš„è¾¨è­˜å‡½æ•¸"""
            if image is None:
                return "âŒ è«‹å…ˆä¸Šå‚³åœ–ç‰‡", "è«‹å…ˆä¸Šå‚³åœ–ç‰‡"
            
            try:
                if use_all_models:
                    # ä½¿ç”¨å¤šæ¨¡å‹ç¶œåˆè¾¨è­˜
                    all_results = classify_with_all_models(image)
                    comprehensive = all_results.get("ğŸ¯ ç¶œåˆè¾¨è­˜çµæœ", {})
                    
                    if "éŒ¯èª¤" in comprehensive:
                        return f"âŒ è¾¨è­˜å¤±æ•—: {comprehensive.get('éŒ¯èª¤', 'æœªçŸ¥éŒ¯èª¤')}", "âš ï¸ å¤šæ¨¡å‹è¾¨è­˜å¤±æ•—"
                    
                    quick_text = f"é£Ÿç‰©: {comprehensive.get('æœ€çµ‚è¾¨è­˜', 'N/A')}\n"
                    quick_text += f"è‹±æ–‡å: {comprehensive.get('è‹±æ–‡å', 'N/A')}\n"
                    quick_text += f"äº”æ€§: {comprehensive.get('äº”æ€§å±¬æ€§', 'N/A')}\n"
                    quick_text += f"æ¨¡å‹å…±è­˜åº¦: {comprehensive.get('æ¨¡å‹å…±è­˜åº¦', 'N/A')}\n"
                    quick_text += f"æˆåŠŸæ¨¡å‹æ•¸: {comprehensive.get('æˆåŠŸæ¨¡å‹æ•¸', 'N/A')}\n"
                    quick_text += "è©³ç´°çµæœè«‹æŸ¥çœ‹ä¸‹æ–¹åˆ†é "
                    
                    status = "âœ… å¤šæ¨¡å‹ç¶œåˆè¾¨è­˜å®Œæˆï¼"
                else:
                    # ä½¿ç”¨å–®ä¸€æ¨¡å‹è¾¨è­˜
                    result = classify_food_image(image, model_name or "swin_model_94")
                    
                    if "éŒ¯èª¤" in result:
                        return f"âŒ è¾¨è­˜å¤±æ•—: {result.get('éŒ¯èª¤', 'æœªçŸ¥éŒ¯èª¤')}", "âš ï¸ è¾¨è­˜é‡åˆ°å•é¡Œ"
                    
                    quick_text = f"é£Ÿç‰©: {result.get('è¾¨è­˜é£Ÿç‰©', 'N/A')}\n"
                    quick_text += f"è‹±æ–‡å: {result.get('è‹±æ–‡å', 'N/A')}\n"
                    quick_text += f"äº”æ€§: {result.get('äº”æ€§å±¬æ€§', 'N/A')}\n"
                    quick_text += f"ä½¿ç”¨æ¨¡å‹: {result.get('ä½¿ç”¨æ¨¡å‹', 'N/A')}\n"
                    quick_text += f"ä¿¡å¿ƒåº¦: {result.get('ä¿¡å¿ƒåº¦', 'N/A')}\n"
                    quick_text += f"é‹è¡Œæ¨¡å¼: {result.get('æ¨¡å¼', 'N/A')}"
                    
                    status = f"âœ… ä½¿ç”¨ {model_name or 'swin_model_94'} è¾¨è­˜å®Œæˆï¼"
                
                return quick_text, status
            except Exception as e:
                error_text = f"âŒ è¾¨è­˜å¤±æ•—: {str(e)}"
                return error_text, f"âŒ è¾¨è­˜å¤±æ•—: {str(e)}"        
        def update_comprehensive_result(image):
            if image is None:
                return "", "", "è«‹å…ˆä¸Šå‚³åœ–ç‰‡"
            
            try:
                # åŸ·è¡Œç¶œåˆè¾¨è­˜
                all_results = classify_with_all_models(image)
                
                # åˆ†é›¢ç¶œåˆçµæœå’Œè©³ç´°çµæœ
                comprehensive = all_results.get("ğŸ¯ ç¶œåˆè¾¨è­˜çµæœ", {})
                detailed = all_results.get("ğŸ“Š å„æ¨¡å‹è©³ç´°çµæœ", {})
                  # æ ¼å¼åŒ–çµæœ
                comprehensive_text = format_comprehensive_result(comprehensive)
                detailed_text = format_detailed_result(detailed)
                
                status = "âœ… æ‰€æœ‰æ¨¡å‹è¾¨è­˜å®Œæˆï¼" if comprehensive and "éŒ¯èª¤" not in comprehensive else "âš ï¸ è¾¨è­˜é‡åˆ°å•é¡Œ"
                
                return comprehensive_text, detailed_text, status
            except Exception as e:
                error_text = f"âŒ è¾¨è­˜éç¨‹ç™¼ç”ŸéŒ¯èª¤: {str(e)}"
                return error_text, "", f"âŒ è¾¨è­˜å¤±æ•—: {str(e)}"
        
        def update_single_result(image, model_name):
            if image is None:
                return "âŒ è«‹å…ˆä¸Šå‚³åœ–ç‰‡", "è«‹å…ˆä¸Šå‚³åœ–ç‰‡"
            
            try:
                result = classify_food_image(image, model_name)
                formatted_result = format_single_result(result)
                status = f"âœ… ä½¿ç”¨ {model_name} è¾¨è­˜å®Œæˆï¼" if "éŒ¯èª¤" not in result else f"âš ï¸ {model_name} è¾¨è­˜å¤±æ•—"
                return formatted_result, status
            except Exception as e:
                error_text = f"âŒ è¾¨è­˜éç¨‹ç™¼ç”ŸéŒ¯èª¤: {str(e)}"
                return error_text, f"âŒ {model_name} è¾¨è­˜å¤±æ•—: {str(e)}"

        def load_sample_image(image_filename):
            """è¼‰å…¥ç¯„ä¾‹åœ–ç‰‡çš„å‡½æ•¸"""
            try:
                image_path = f"./assets/images/{image_filename}"
                if os.path.exists(image_path):
                    from PIL import Image
                    image = Image.open(image_path)
                    return image, f"âœ… å·²è¼‰å…¥ç¯„ä¾‹åœ–ç‰‡: {image_filename}"
                else:
                    return None, f"âŒ æ‰¾ä¸åˆ°ç¯„ä¾‹åœ–ç‰‡: {image_filename}"
            except Exception as e:
                return None, f"âŒ è¼‰å…¥ç¯„ä¾‹åœ–ç‰‡å¤±æ•—: {str(e)}"

        # ä½¿ç”¨èªªæ˜éƒ¨åˆ†
        with gr.Column(elem_classes=["food-result-section"]):
            gr.HTML("""
            <div style="text-align: center; margin-bottom: 30px;">
                <h3 style="color: #4A6741; font-size: 1.8rem; margin-bottom: 20px;">ğŸ“‹ ä½¿ç”¨èªªæ˜</h3>
            </div>
            """)
            
            with gr.Row(elem_classes=["food-feature-cards-row"]):
                with gr.Column(elem_classes=["food-feature-card"]):
                    gr.HTML("""
                    <div class="food-feature-icon">ğŸ“¸</div>
                    <h4 class="food-feature-title">1. ä¸Šå‚³åœ–ç‰‡</h4>
                    <p class="food-feature-description">
                        é¸æ“‡æ¸…æ™°çš„é£Ÿç‰©åœ–ç‰‡ï¼Œå»ºè­°å…‰ç·šå……è¶³ã€ä¸»é«”æ˜é¡¯çš„å–®ä¸€é£Ÿç‰©ç…§ç‰‡
                    </p>
                    """)
                
                with gr.Column(elem_classes=["food-feature-card"]):
                    gr.HTML("""
                    <div class="food-feature-icon">ğŸ¯</div>
                    <h4 class="food-feature-title">2. é¸æ“‡è¾¨è­˜æ–¹å¼</h4>
                    <p class="food-feature-description">
                        å¤šæ¨¡å‹ç¶œåˆè¾¨è­˜ï¼š6å€‹AIæ¨¡å‹æŠ•ç¥¨çµæœï¼Œæº–ç¢ºåº¦æ›´é«˜<br>
                        å–®ä¸€æ¨¡å‹è¾¨è­˜ï¼šé¸æ“‡ç‰¹å®šæ¨¡å‹é€²è¡Œå¿«é€Ÿè¾¨è­˜
                    </p>
                    """)
                
                with gr.Column(elem_classes=["food-feature-card"]):
                    gr.HTML("""
                    <div class="food-feature-icon">ğŸ“Š</div>
                    <h4 class="food-feature-title">3. æŸ¥çœ‹çµæœ</h4>
                    <p class="food-feature-description">
                        ç²å¾—é£Ÿç‰©åç¨±ã€è‹±æ–‡å°ç…§ã€ä¸­é†«äº”æ€§å±¬æ€§åˆ†æï¼Œäº†è§£é£Ÿç‰©å¯’ç†±ç‰¹æ€§
                    </p>
                    """)
        
        # å…è²¬è²æ˜
        with gr.Column(elem_classes=["food-result-section"]):
            gr.HTML("""
            <div style="text-align: center; margin-bottom: 20px;">
                <h3 style="color: #8B4513; font-size: 1.6rem; margin-bottom: 15px;">âš ï¸ é‡è¦è²æ˜</h3>
            </div>
            <div style="background: linear-gradient(135deg, #FFF8E1 0%, #FFFBF0 100%); 
                        border: 2px solid rgba(139, 69, 19, 0.2); 
                        border-radius: 15px; 
                        padding: 25px; 
                        color: #8B4513; 
                        line-height: 1.6;
                        font-size: 0.95rem;">
                <p style="margin: 0 0 15px 0;">
                    <strong>ğŸ”¬ é—œæ–¼AIè¾¨è­˜ï¼š</strong><br>
                    æœ¬ç³»çµ±ä½¿ç”¨æ·±åº¦å­¸ç¿’æŠ€è¡“é€²è¡Œé£Ÿç‰©è¾¨è­˜ï¼Œé›–ç¶“éå¤§é‡æ•¸æ“šè¨“ç·´ï¼Œä½†ä»å¯èƒ½å­˜åœ¨è¾¨è­˜éŒ¯èª¤çš„æƒ…æ³ã€‚
                    è¾¨è­˜çµæœåƒ…ä¾›åƒè€ƒï¼Œè«‹ä»¥å¯¦éš›é£Ÿç‰©ç‚ºæº–ã€‚
                </p>
                <p style="margin: 0 0 15px 0;">
                    <strong>ğŸŒ¡ï¸ é—œæ–¼ä¸­é†«å±¬æ€§ï¼š</strong><br>
                    é£Ÿç‰©äº”æ€§ï¼ˆå¯’ã€æ¶¼ã€å¹³ã€æº«ã€ç†±ï¼‰è³‡è¨ŠåŸºæ–¼å‚³çµ±ä¸­é†«ç†è«–æ•´ç†ï¼Œ
                    å€‹äººé«”è³ªä¸åŒï¼Œå»ºè­°è«®è©¢å°ˆæ¥­ä¸­é†«å¸«ç²å¾—å€‹äººåŒ–å»ºè­°ã€‚
                </p>
                <p style="margin: 0;">
                    <strong>âš•ï¸ å¥åº·æé†’ï¼š</strong><br>
                    æœ¬ç³»çµ±ä¸èƒ½æ›¿ä»£å°ˆæ¥­é†«ç™‚å»ºè­°ï¼Œå¦‚æœ‰å¥åº·å•é¡Œæˆ–ç‰¹æ®Šé£²é£Ÿéœ€æ±‚ï¼Œ
                    è«‹è«®è©¢åˆæ ¼çš„é†«ç™‚å°ˆæ¥­äººå“¡æˆ–ç‡Ÿé¤Šå¸«ã€‚
                </p>
            </div>            """)        
            
        food_state = gr.State()
        
        # å‰µå»ºä¸€å€‹å¯è¦‹çš„æŒ‰éˆ•ï¼Œä¸¦æ‡‰ç”¨æ¼‚æµ®æ¨£å¼
        # é€™å€‹æŒ‰éˆ•çš„ click äº‹ä»¶æœƒåœ¨ app.py ä¸­è¢«ç¶å®š
        back_to_home_btn = gr.Button(
            "ğŸ  ğŸ”™",
            elem_classes=["floating-return-button"], # æ‡‰ç”¨æ¼‚æµ®æŒ‰éˆ•çš„CSS class
            visible=True  # è¨­ç½®ç‚ºå¯è¦‹
        )
        
        # å¤šæ¨¡å‹ç¶œåˆè¾¨è­˜æŒ‰éˆ•äº‹ä»¶
        recognize_all_btn.click(
            fn=update_comprehensive_result,
            inputs=[food_image],
            outputs=[comprehensive_result_display, detailed_result_display, status_display],
            api_name="recognize_all_food_models",
            show_progress=True
        )
        
        # å–®ä¸€æ¨¡å‹è¾¨è­˜æŒ‰éˆ•äº‹ä»¶
        # single_model_btn.click(
        #     fn=update_single_result,
        #     inputs=[food_image, model_name_input],
        #     outputs=[single_result_display, status_display],
        #     api_name="recognize_single_food_model",
        #     show_progress=True
        # )
        
        # ç¯„ä¾‹åœ–ç‰‡æŒ‰éˆ•äº‹ä»¶ç¶å®š
        for btn, filename in sample_buttons:
            btn.click(
                fn=load_sample_image,
                inputs=[gr.State(filename)],
                outputs=[food_image, status_display],
                show_progress=True
            )
        
        # è¿”å›ä¸»é æŒ‰éˆ•äº‹ä»¶å·²åœ¨ app.py ä¸­çµ±ä¸€è™•ç†
    
    return None, food_state, back_to_home_btn

def load_swin_model(model_name: str, model_path: str = None):
    """
    å°ˆé–€è¼‰å…¥ Swin Transformer æ¨¡å‹çš„å‡½æ•¸
    è™•ç† Swin æ¨¡å‹ç‰¹æœ‰çš„ relative position åƒæ•¸å•é¡Œ
    """
    if model_path is None:
        model_path = f"./model/{model_name}.pth"
    
    if not os.path.exists(model_path):
        print(f"âŒ Swin æ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨: {model_path}ï¼Œä½¿ç”¨æ¨¡æ“¬æ¨¡å¼")
        return None
    
    try:
        print(f"Loading Swin model from {model_path}...")
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # è¼‰å…¥æª¢æŸ¥é»
        state_dict = torch.load(model_path, map_location=device)
        
        # è™•ç†å¯èƒ½çš„ DataParallel æˆ– DistributedDataParallel åŒ…è£
        if 'module.' in list(state_dict.keys())[0]:
            # ç§»é™¤ 'module.' å‰ç¶´
            new_state_dict = {}
            for key, value in state_dict.items():
                new_key = key.replace('module.', '')
                new_state_dict[new_key] = value
            state_dict = new_state_dict
            print("Removed 'module.' prefix from state dict keys")
        
        # æª¢æ¸¬é¡åˆ¥æ•¸é‡ - å¾ head.fc æˆ– head.weight ä¸­ç²å–
        num_classes = 183  # é è¨­å€¼
        if 'head.fc.weight' in state_dict:
            num_classes = state_dict['head.fc.weight'].shape[0]
        elif 'head.weight' in state_dict:
            num_classes = state_dict['head.weight'].shape[0]
        
        print(f"Detected {num_classes} classes")
        
        # å»ºç«‹æ¨¡å‹æ¶æ§‹ - æ ¹æ“šæ¨¡å‹åç¨±é¸æ“‡æ­£ç¢ºçš„æ¶æ§‹
        if 'swinv2' in model_name.lower():
            # Swin Transformer V2
            model = timm.create_model('swinv2_base_window12_192', 
                                    pretrained=False, 
                                    num_classes=num_classes)
        else:
            # Swin Transformer V1 (é è¨­)
            model = timm.create_model('swin_base_patch4_window7_224', 
                                    pretrained=False, 
                                    num_classes=num_classes)
        
        # è¼‰å…¥æ¬Šé‡
        try:
            model.load_state_dict(state_dict)
            print("Successfully loaded model with all keys matching")
        except RuntimeError as e:
            # å¦‚æœæœ‰ä¸åŒ¹é…çš„éµï¼Œä½¿ç”¨ strict=False
            missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)
            
            # åˆ†æç¼ºå¤±å’Œå¤šé¤˜çš„éµ
            swin_specific_keys = []
            other_missing_keys = []
            
            for key in missing_keys:
                if any(pattern in key for pattern in ['relative_position_bias_table', 'relative_position_index', 'attn_mask']):
                    swin_specific_keys.append(key)
                else:
                    other_missing_keys.append(key)
            
            if swin_specific_keys:
                print(f"âœ… Swin æ¨¡å‹ç‰¹å®šåƒæ•¸å°‡ç”±æ¨¡å‹è‡ªå‹•åˆå§‹åŒ–: {len(swin_specific_keys)} å€‹åƒæ•¸")
            
            if other_missing_keys:
                print(f"âš ï¸ å…¶ä»–ç¼ºå¤±çš„éµ: {other_missing_keys}")
            
            if unexpected_keys:
                print(f"âš ï¸ æœªé æœŸçš„éµ: {unexpected_keys[:10]}...")
        
        model = model.to(device)
        model.eval()
        
        print(f"âœ… æˆåŠŸè¼‰å…¥ Swin æ¨¡å‹: {model_name} (é¡åˆ¥æ•¸: {num_classes})")
        return model
        
    except Exception as e:
        print(f"âŒ è¼‰å…¥ Swin æ¨¡å‹å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return None

def load_efficientnet_model(model_name: str, model_path: str = None):
    """
    å°ˆé–€è¼‰å…¥ EfficientNet æ¨¡å‹çš„å‡½æ•¸
    ä½¿ç”¨æ¨™æº–çš„ torchvision EfficientNet æ¶æ§‹
    """
    if model_path is None:
        model_path = f"./model/{model_name}.pth"
    
    if not os.path.exists(model_path):
        print(f"âŒ EfficientNet æ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨: {model_path}ï¼Œä½¿ç”¨æ¨¡æ“¬æ¨¡å¼")
        return None
    
    try:
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # è¼‰å…¥æª¢æŸ¥é»
        checkpoint = torch.load(model_path, map_location=device)
        
        # æå– state_dict
        if isinstance(checkpoint, dict):
            if 'model_state_dict' in checkpoint:
                state_dict = checkpoint['model_state_dict']
            elif 'state_dict' in checkpoint:
                state_dict = checkpoint['state_dict']
            else:
                state_dict = checkpoint
        else:
            state_dict = checkpoint.state_dict() if hasattr(checkpoint, 'state_dict') else checkpoint
        
        # æ¸…ç†éµåï¼Œå»é™¤å¯èƒ½çš„ module. å‰ç¶´ï¼ˆç”¨æ–¼è™•ç† DataParallel è¨“ç·´çš„æ¨¡å‹ï¼‰
        cleaned_state_dict = {}
        for k, v in state_dict.items():
            name = k.replace("module.", "") if k.startswith("module.") else k
            cleaned_state_dict[name] = v
        
        # å¾ classifier.1 å±¤æª¢æ¸¬é¡åˆ¥æ•¸é‡
        num_classes = 183  # é è¨­å€¼
        if 'classifier.1.weight' in cleaned_state_dict:
            num_classes = cleaned_state_dict['classifier.1.weight'].shape[0]
        elif 'classifier.1.out_features' in cleaned_state_dict:
            num_classes = cleaned_state_dict['classifier.1.out_features']
        
        # ä½¿ç”¨æ¨™æº–çš„ torchvision EfficientNet-B5 æ¶æ§‹
        from torchvision import models
        import torch.nn as nn
        
        model = models.efficientnet_b5(weights=None)  # ä¸è¼‰å…¥é è¨“ç·´æ¬Šé‡
        
        # ä¿®æ”¹åˆ†é¡å™¨çš„æœ€å¾Œä¸€å±¤ä»¥åŒ¹é…é¡åˆ¥æ•¸
        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)
        
        model = model.to(device)
        
        # è¼‰å…¥æ¨¡å‹æ¬Šé‡
        missing_keys, unexpected_keys = model.load_state_dict(cleaned_state_dict, strict=False)
        
        if missing_keys:
            print(f"âš ï¸ EfficientNet ç¼ºå¤±çš„éµ: {missing_keys[:5]}..." if len(missing_keys) > 5 else f"âš ï¸ EfficientNet ç¼ºå¤±çš„éµ: {missing_keys}")
        
        if unexpected_keys:
            print(f"âš ï¸ EfficientNet æœªé æœŸçš„éµ: {unexpected_keys[:5]}..." if len(unexpected_keys) > 5 else f"âš ï¸ EfficientNet æœªé æœŸçš„éµ: {unexpected_keys}")
        
        model.eval()
        print(f"âœ… æˆåŠŸè¼‰å…¥ EfficientNet æ¨¡å‹: {model_name} (é¡åˆ¥æ•¸: {num_classes})")
        return model
        
    except Exception as e:
        print(f"âŒ è¼‰å…¥ EfficientNet æ¨¡å‹å¤±æ•—: {e}")
        return None

def load_convnext_model(model_name: str, model_path: str = None):
    """å°ˆé–€è¼‰å…¥ ConvNeXt æ¨¡å‹çš„å‡½æ•¸"""
    if model_path is None:
        model_path = f"./model/{model_name}.pth"
    
    if not os.path.exists(model_path):
        print(f"âŒ ConvNeXt æ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨: {model_path}ï¼Œä½¿ç”¨æ¨¡æ“¬æ¨¡å¼")
        return None
    
    try:
        print(f"Loading ConvNeXt model from {model_path}...")
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # å…ˆè¼‰å…¥æ¬Šé‡æª¢æŸ¥é¡åˆ¥æ•¸
        checkpoint = torch.load(model_path, map_location=device)
        
        # æ¸…ç†éµåï¼Œç§»é™¤ module. å‰ç¶´ï¼ˆDataParallel è¨“ç·´ç”¢ç”Ÿçš„ï¼‰
        cleaned_state_dict = {}
        for k, v in checkpoint.items():
            name = k.replace("module.", "") if k.startswith("module.") else k
            cleaned_state_dict[name] = v
        
        # æª¢æ¸¬é¡åˆ¥æ•¸ï¼ˆConvNeXt çš„åˆ†é¡å™¨åœ¨ classifier.2ï¼‰
        classifier_key = 'classifier.2.weight'
        num_classes = None
        
        if classifier_key in cleaned_state_dict:
            num_classes = cleaned_state_dict[classifier_key].shape[0]
            print(f"Found classifier layer '{classifier_key}' with {num_classes} classes")
        else:
            # å¦‚æœæ‰¾ä¸åˆ°æ¨™æº–çš„åˆ†é¡å™¨éµï¼Œæœå°‹å…¶ä»–å¯èƒ½çš„åˆ†é¡å™¨å±¤
            for key in cleaned_state_dict.keys():
                if 'classifier' in key and 'weight' in key and len(cleaned_state_dict[key].shape) == 2:
                    classifier_key = key
                    num_classes = cleaned_state_dict[key].shape[0]
                    print(f"Found classifier layer '{classifier_key}' with {num_classes} classes")
                    break
        
        if num_classes is None:
            raise ValueError("ç„¡æ³•å¾æ¨¡å‹æ¬Šé‡ä¸­æª¢æ¸¬åˆ°é¡åˆ¥æ•¸")
        
        # ä½¿ç”¨ torchvision ConvNeXt æ¶æ§‹
        from torchvision import models
        import torch.nn as nn
        
        model = models.convnext_base(weights=None)
        
        # ä¿®æ”¹åˆ†é¡å™¨å±¤ï¼ˆConvNeXt çš„åˆ†é¡å™¨åœ¨ index 2ï¼‰
        model.classifier[2] = nn.Linear(model.classifier[2].in_features, num_classes)
        
        # è¼‰å…¥æ¬Šé‡ï¼ˆä½¿ç”¨æ¸…ç†å¾Œçš„ state_dictï¼‰
        missing_keys, unexpected_keys = model.load_state_dict(cleaned_state_dict, strict=False)
        
        if missing_keys:
            print(f"Missing keys: {missing_keys[:5]}...")  # åªé¡¯ç¤ºå‰5å€‹
        if unexpected_keys:
            print(f"Unexpected keys: {unexpected_keys[:5]}...")  # åªé¡¯ç¤ºå‰5å€‹
        
        model.to(device)
        model.eval()
        
        print("ConvNeXt model loaded successfully!")
        return model
        
    except Exception as e:
        print(f"Error loading ConvNeXt model: {str(e)}")
        return None

def load_vgg_model(model_name: str, model_path: str = None):
    """
    å°ˆé–€è¼‰å…¥ VGG æ¨¡å‹çš„å‡½æ•¸
    ä½¿ç”¨æ¨™æº–çš„ torchvision VGG16 æ¶æ§‹
    """
    if model_path is None:
        model_path = f"./model/{model_name}.pth"
    
    if not os.path.exists(model_path):
        print(f"âŒ VGG æ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨: {model_path}ï¼Œä½¿ç”¨æ¨¡æ“¬æ¨¡å¼")
        return None
    
    try:
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # è¼‰å…¥æª¢æŸ¥é»
        checkpoint = torch.load(model_path, map_location=device)
        
        # æå– state_dict
        if isinstance(checkpoint, dict):
            if 'model_state_dict' in checkpoint:
                state_dict = checkpoint['model_state_dict']
            elif 'state_dict' in checkpoint:
                state_dict = checkpoint['state_dict']
            else:
                state_dict = checkpoint
        else:
            state_dict = checkpoint.state_dict() if hasattr(checkpoint, 'state_dict') else checkpoint
        
        # æ¸…ç†éµåï¼Œå»é™¤å¯èƒ½çš„ module. å‰ç¶´
        cleaned_state_dict = {}
        for k, v in state_dict.items():
            name = k.replace("module.", "") if k.startswith("module.") else k
            cleaned_state_dict[name] = v
        
        # å¾ classifier.6 å±¤æª¢æ¸¬é¡åˆ¥æ•¸é‡
        num_classes = 183  # é è¨­å€¼
        if 'classifier.6.weight' in cleaned_state_dict:
            num_classes = cleaned_state_dict['classifier.6.weight'].shape[0]
        elif 'classifier.6.out_features' in cleaned_state_dict:
            num_classes = cleaned_state_dict['classifier.6.out_features']
        
        # ä½¿ç”¨æ¨™æº–çš„ torchvision VGG16 æ¶æ§‹
        from torchvision import models
        import torch.nn as nn
        
        model = models.vgg16(weights=None)  # ä¸è¼‰å…¥é è¨“ç·´æ¬Šé‡
        
        # ä¿®æ”¹æœ€å¾Œçš„åˆ†é¡å±¤ä»¥åŒ¹é…é¡åˆ¥æ•¸
        model.classifier[6] = nn.Linear(4096, num_classes)
        
        model = model.to(device)
        
        # è¼‰å…¥æ¨¡å‹æ¬Šé‡
        missing_keys, unexpected_keys = model.load_state_dict(cleaned_state_dict, strict=False)
        
        if missing_keys:
            print(f"âš ï¸ VGG ç¼ºå¤±çš„éµ: {missing_keys[:5]}..." if len(missing_keys) > 5 else f"âš ï¸ VGG ç¼ºå¤±çš„éµ: {missing_keys}")
        
        if unexpected_keys:
            print(f"âš ï¸ VGG æœªé æœŸçš„éµ: {unexpected_keys[:5]}..." if len(unexpected_keys) > 5 else f"âš ï¸ VGG æœªé æœŸçš„éµ: {unexpected_keys}")
        
        model.eval()
        print(f"âœ… æˆåŠŸè¼‰å…¥ VGG æ¨¡å‹: {model_name} (é¡åˆ¥æ•¸: {num_classes})")
        return model
        
    except Exception as e:
        print(f"âŒ è¼‰å…¥ VGG æ¨¡å‹å¤±æ•—: {e}")
        return None

